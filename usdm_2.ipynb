{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: yfiles_jupyter_graphs in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.4.3)\n",
      "Requirement already satisfied: ipywidgets>=7.6.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from yfiles_jupyter_graphs) (8.0.4)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (3.0.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.8.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (6.20.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (8.8.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (4.0.5)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (25.0.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.1.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.1.6)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (6.2)\n",
      "Requirement already satisfied: nest-asyncio in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.5.6)\n",
      "Requirement already satisfied: appnope in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.1.3)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (21.3)\n",
      "Requirement already satisfied: debugpy>=1.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.6.5)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (7.4.8)\n",
      "Requirement already satisfied: psutil in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.9.4)\n",
      "Requirement already satisfied: stack-data in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.6.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (3.0.36)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.7.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.13.0)\n",
      "Requirement already satisfied: decorator in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.1.1)\n",
      "Requirement already satisfied: backcall in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.18.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.1.3)\n",
      "Requirement already satisfied: entrypoints in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (3.0.6)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.2.2)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.16.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.6.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install openpyxl\n",
    "%pip install yfiles_jupyter_graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from yfiles_jupyter_graphs import GraphWidget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_ROW = 0\n",
    "CYCLE_ROW = 1\n",
    "CYCLE_START_ROW = 2\n",
    "CYCLE_PERIOD_ROW = 3\n",
    "CYCLE_END_RULE_ROW = 4\n",
    "TIMING_ROW = 5\n",
    "VISIT_LABEL_ROW = 6\n",
    "VISIT_WINDOW_ROW = 7\n",
    "\n",
    "FIRST_ACTIVITY_ROW = 8\n",
    "\n",
    "ACTIVITY_COL = 0\n",
    "CHILD_ACTIVITY_COL = 1\n",
    "BC_COL = 2\n",
    "PROFILE_COL = 3\n",
    "FIRST_VISIT_COL = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cycle_cell(df, row_index, col_index):\n",
    "  is_null = pd.isnull(df.iloc[row_index, col_index])\n",
    "  if is_null:\n",
    "    return \"\", True\n",
    "  else:\n",
    "    value = str(df.iloc[row_index, col_index])\n",
    "    if value.upper() == \"-\":\n",
    "      return \"\", True\n",
    "    else:\n",
    "      return value, False\n",
    "\n",
    "def previous_index(index):\n",
    "  if index == 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return index - 1\n",
    "\n",
    "def build_cycle_record(df, index, col_index, condition):\n",
    "  cycle_start_index = index\n",
    "  cycle_start, is_null = get_cycle_cell(df, CYCLE_START_ROW, col_index)\n",
    "  cycle_period, is_null = get_cycle_cell(df, CYCLE_PERIOD_ROW, col_index)\n",
    "  cycle_end_rule, is_null = get_cycle_cell(df, CYCLE_END_RULE_ROW, col_index)\n",
    "  return { \n",
    "    'start_index': cycle_start_index, \n",
    "    'condition': condition, \n",
    "    'start': cycle_start, \n",
    "    'period': cycle_period, \n",
    "    'end_rule': cycle_end_rule \n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cycles(df):\n",
    "  cycles = []\n",
    "  timepoint_index = -1\n",
    "  cycle_start_index = None\n",
    "  in_cycle = False\n",
    "  prev_cycle = None\n",
    "  for col_index in range(df.shape[1]):\n",
    "    if col_index >= FIRST_VISIT_COL:\n",
    "      timepoint_index += 1\n",
    "      cycle, cycle_is_null = get_cycle_cell(df, CYCLE_ROW, col_index)\n",
    "      if cycle_is_null:\n",
    "        if in_cycle:\n",
    "          cycle_record['end_index'] = previous_index(timepoint_index)\n",
    "          cycles.append(cycle_record)\n",
    "          in_cycle = False\n",
    "        else:\n",
    "          pass # Do nothing\n",
    "      else:\n",
    "        cycle = str(cycle)\n",
    "        if not in_cycle:\n",
    "          in_cycle = True\n",
    "          cycle_record = build_cycle_record(df, timepoint_index, col_index, cycle)\n",
    "        elif prev_cycle == cycle:\n",
    "          pass # Do nothing\n",
    "        else:\n",
    "          cycle_record['end_index'] = previous_index(timepoint_index)\n",
    "          cycles.append(cycle_record)\n",
    "          cycle_record = build_cycle_record(df, timepoint_index, col_index, cycle)\n",
    "      prev_cycle = cycle\n",
    "  return cycles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timing_cell(df, row_index, col_index):\n",
    "  is_null = pd.isnull(df.iloc[row_index, col_index])\n",
    "  if is_null:\n",
    "    return \"\", True\n",
    "  else:\n",
    "    return df.iloc[row_index, col_index], False\n",
    "\n",
    "def get_relative_ref(part):\n",
    "  if len(part) > 1:\n",
    "    return int(part[1:])\n",
    "  else:\n",
    "    return 1\n",
    "\n",
    "def get_timing_type(df, col_index):\n",
    "  timing_type = \"\"\n",
    "  rel_ref = 0\n",
    "  timing_value = \"\"\n",
    "  timing_info, timing_info_is_null = get_timing_cell(df, TIMING_ROW, col_index)\n",
    "  if not timing_info_is_null:\n",
    "    timing_parts = timing_info.split(\":\")\n",
    "    if timing_parts[0].upper()[0] == \"A\":\n",
    "      timing_type = \"anchor\"\n",
    "      rel_ref = 0\n",
    "    if timing_parts[0].upper()[0] == \"P\":\n",
    "      timing_type = \"previous\"\n",
    "      rel_ref = get_relative_ref(timing_parts[0]) * -1\n",
    "    elif timing_parts[0].upper()[0] == \"N\":\n",
    "      timing_type = \"next\"\n",
    "      rel_ref = get_relative_ref(timing_parts[0])\n",
    "    if len(timing_parts) == 2:\n",
    "      timing_value = timing_parts[1].strip()\n",
    "  #print(\"TIMING: col_index (%s) - FIRST_VISIT_COL (%s) + rel_ref (%s)\" % (col_index, FIRST_VISIT_COL, rel_ref))\n",
    "  return { 'type': timing_type, 'ref': col_index - FIRST_VISIT_COL + rel_ref, 'value': timing_value }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timepoints(df):\n",
    "  timepoints = []\n",
    "  for col_index in range(df.shape[1]):\n",
    "    if col_index >= FIRST_VISIT_COL:\n",
    "      record = get_timing_type(df, col_index)\n",
    "      timepoints.append(record)\n",
    "  return timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encounter_cell(df, row_index, col_index):\n",
    "  is_null = pd.isnull(df.iloc[row_index, col_index])\n",
    "  if is_null:\n",
    "    return \"\", True\n",
    "  else:\n",
    "    return df.iloc[row_index, col_index], False\n",
    "\n",
    "def get_encounter_details(df, col_index):\n",
    "  label = \"\"\n",
    "  window = \"\"\n",
    "  label, label_is_null = get_encounter_cell(df, VISIT_LABEL_ROW, col_index)\n",
    "  window, window_is_null = get_encounter_cell(df, VISIT_WINDOW_ROW, col_index)\n",
    "  return { 'label': label, 'window': window }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_encounters(df):\n",
    "  encounters = []\n",
    "  for col_index in range(df.shape[1]):\n",
    "    if col_index >= FIRST_VISIT_COL:\n",
    "      record = get_encounter_details(df, col_index)\n",
    "      encounters.append(record)\n",
    "  return encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_cell(df, row_index, col_index):\n",
    "  is_null = pd.isnull(df.iloc[row_index, col_index])\n",
    "  if is_null:\n",
    "    return \"\", True\n",
    "  else:\n",
    "    return df.iloc[row_index, col_index], False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activities_and_bcs(df):\n",
    "  activities = []\n",
    "  activities_bc_map = {}\n",
    "  row_activities_map = []\n",
    "  prev_activity = None\n",
    "  for row_index, col_def in df.iterrows():\n",
    "    if row_index >= FIRST_ACTIVITY_ROW:\n",
    "      activity, activity_is_null = get_activity_cell(df, row_index, CHILD_ACTIVITY_COL)\n",
    "      if activity_is_null:\n",
    "        if not prev_activity == None:\n",
    "          row_activities_map.append(prev_activity)\n",
    "      else:\n",
    "        activities.append(activity)\n",
    "        row_activities_map.append(activity)\n",
    "      prev_activity = activity\n",
    "      bc, bc_is_null = get_activity_cell(df, row_index, BC_COL)\n",
    "      if not bc_is_null:\n",
    "        if not activity in activities_bc_map:\n",
    "          activities_bc_map[activity] = { 'bc': [] }  \n",
    "        activities_bc_map[activity]['bc'].append(bc)\n",
    "  return { \n",
    "    'activities': activities,\n",
    "    'activity_bc_map': activities_bc_map,\n",
    "    'row_activities_map': row_activities_map\n",
    "  }\n",
    "\n",
    "def extract_timepoint_activities_map(df, timepoints, activities, row_activities_map):\n",
    "  timepoint_activity_map = []\n",
    "  activity_dict = {}\n",
    "  for activity in activities:\n",
    "    activity_dict[activity] = False\n",
    "  for tp in timepoints:\n",
    "    timepoint_activity_map.append(activity_dict)\n",
    "  for index in range(df.shape[1]):\n",
    "    if index >= FIRST_VISIT_COL:\n",
    "      column = df.iloc[:, index]\n",
    "      row = 0\n",
    "      for col in column:\n",
    "        if row >= FIRST_ACTIVITY_ROW:\n",
    "          if not pd.isnull(col):\n",
    "            if col.upper() == \"X\":\n",
    "              activity = row_activities_map[row - FIRST_ACTIVITY_ROW]\n",
    "              tp_index = index - FIRST_VISIT_COL\n",
    "              timepoint_activity_map[tp_index][activity] = True\n",
    "        row += 1\n",
    "  return timepoint_activity_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDFJson():\n",
    "  \n",
    "  def __init__(self):\n",
    "    self.id_index = { 'entry': 0, 'exit': 0, 'timepoint': 0, 'timeline': 0, 'timing': 0 }\n",
    "    self.dicts = {}\n",
    "\n",
    "  def increment_index(self, name):\n",
    "    self.id_index[name] += 1\n",
    "\n",
    "  def build_id(self, name):\n",
    "    self.increment_index(name)\n",
    "    return \"%s_%s\" % (name, self.id_index[name])\n",
    "\n",
    "  def add_entry(self, description, timepoint_id):\n",
    "    id = self.build_id('entry')\n",
    "    result = { '_type': 'Entry', 'entryId': id, 'entryDescription': description, 'nextTimepointId': timepoint_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_exit(self):\n",
    "    id = self.build_id('exit')\n",
    "    result = { '_type': 'Exit', 'exitId': id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_timepoint(self, previous_timepoint_id, timing):\n",
    "    id = self.build_id('timepoint')\n",
    "    result = { '_type': 'Timepoint', 'timepointId': id, 'nextTimepointId': None, 'scheduledAt': timing }\n",
    "    self.dicts[id] = result\n",
    "    if not previous_timepoint_id == None:\n",
    "      self.dicts[previous_timepoint_id]['nextTimepointId'] = id\n",
    "    return result\n",
    "\n",
    "  def add_previous_timing(self, value, relative_to_from, window, to_id):\n",
    "    id = self.build_id('timing')\n",
    "    result = { '_type': 'Timing', 'timingId': id, 'type': \"after\", 'value': value, 'relativeToFrom': relative_to_from, 'window': window, 'relativeTo': to_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_next_timing(self, value, relative_to_from, window, to_id):\n",
    "    id = self.build_id('timing')\n",
    "    result = { '_type': 'Timing', 'timingId': id, 'type': \"next\", 'value': value, 'relativeToFrom': relative_to_from, 'window': window, 'relativeTo': to_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_anchor_timing(self, value):\n",
    "    id = self.build_id('timing')\n",
    "    result = { '_type': 'Timing', 'timingId': id, 'type': \"anchor\", 'value': value, 'relativeToFrom': None, 'window': None, 'relativeTo': None }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_timeline(self, entry, timepoints, exit):\n",
    "    id = self.build_id('timeline')\n",
    "    result = { '_type': 'Timeline', 'timelineId': self.build_id('timeline'), 'timelineEntry': entry, 'timelineTimepoints': timepoints, 'timelineExit': exit }\n",
    "    self.dicts['id'] = result\n",
    "    return result\n",
    "  \n",
    "  def process_timepoints(self, timepoints):\n",
    "    tps = []\n",
    "    timing = []\n",
    "    previous_tp_id = None\n",
    "    for timepoint in timepoints:\n",
    "      tps.append(self.add_timepoint(previous_tp_id, None))\n",
    "      previous_tp_id = tps[-1]['timepointId']\n",
    "    for timepoint in timepoints:\n",
    "      if timepoint['type'] == 'next':\n",
    "        timing.append(self.add_next_timing(timepoint['value'], 'StartToStart', None, tps[timepoint['ref']]['timepointId']))\n",
    "      elif timepoint['type'] == 'previous':\n",
    "        timing.append(self.add_previous_timing(timepoint['value'], 'StartToStart', None, tps[timepoint['ref']]['timepointId']))\n",
    "      elif timepoint['type'] == 'anchor':\n",
    "        timing.append(self.add_anchor_timing(timepoint['value']))\n",
    "      elif timepoint['type'] == '':\n",
    "        timing.append({})\n",
    "    for index, tp in enumerate(tps):\n",
    "      tp['scheduledAt'] = timing[index]\n",
    "    entry = self.add_entry('Main timeline', tps[0]['timepointId'])\n",
    "    exit = self.add_exit()\n",
    "    tps[-1]['exit'] = exit\n",
    "    return self.add_timeline(entry, tps, exit)\n",
    "  \n",
    "  def export(self, the_dict):\n",
    "    return self.export_dict(the_dict)\n",
    "\n",
    "  def export_dict(self, the_dict):\n",
    "    cleaned_dict = {}\n",
    "    for key, value in the_dict.items():\n",
    "      if key.startswith('_'):\n",
    "        continue\n",
    "      if type(value) == list:\n",
    "        cleaned_dict[key] = []\n",
    "        for item in value:\n",
    "          cleaned_dict[key].append(self.export_dict(item))\n",
    "      elif type(value) == dict:\n",
    "        cleaned_dict[key] = self.export_dict(value)\n",
    "      else:\n",
    "        cleaned_dict[key] = value\n",
    "    return cleaned_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDFVisual():\n",
    "\n",
    "  def __init__(self):\n",
    "    self.nodes = []\n",
    "    self.edges = []\n",
    "    self.add_edges = []\n",
    "    self.node_index = 1\n",
    "    self.edge_index = 1\n",
    "    self.id_node_index_map = {}\n",
    "    self.type_id_field_map = { \n",
    "      'Entry': 'entryId',\n",
    "      'Exit': 'exitId',\n",
    "      'Timeline': 'timelineId',\n",
    "      'Timepoint': 'timepointId',\n",
    "      'Timing': 'timingId'\n",
    "    }\n",
    "    self.edge_attributes = [\n",
    "      'relativeTo',\n",
    "      'nextTimepointId'\n",
    "    ]\n",
    "    \n",
    "  def get_id_field_and_klass(self, node):\n",
    "    print(\"NODE:\", node)\n",
    "    klass = node['_type']\n",
    "    return self.type_id_field_map[klass], klass\n",
    "\n",
    "  def draw(self, json):\n",
    "    self.process_node(json)\n",
    "    print(\"ADD:\", self.add_edges)\n",
    "    for edge in self.add_edges:\n",
    "      edge['id'] = self.edge_index\n",
    "      edge['end'] = self.id_node_index_map[edge['end']]\n",
    "      self.edges.append(edge)\n",
    "      self.edge_index += 1\n",
    "    return self.nodes, self.edges\n",
    "  \n",
    "  def process_node(self, node):\n",
    "    properties = {}\n",
    "    if node == {}:\n",
    "      return None\n",
    "    id_field, klass = self.get_id_field_and_klass(node)\n",
    "    if node[id_field] in self.id_node_index_map:\n",
    "      return self.id_node_index_map[node[id_field]]\n",
    "    this_node_index = self.node_index\n",
    "    self.node_index += 1\n",
    "    for key, value in node.items():\n",
    "      if type(value) == list:\n",
    "        for item in value:\n",
    "          item_node_index = self.process_node(item)\n",
    "          if not item_node_index == None:\n",
    "            self.edges.append( {'id': self.edge_index, 'start': this_node_index, 'end': item_node_index, 'properties': {'label': key}})\n",
    "            self.edge_index += 1\n",
    "      elif type(value) == dict:\n",
    "        item_node_index = self.process_node(value)\n",
    "        if not item_node_index == None:\n",
    "          self.edges.append( {'id': self.edge_index, 'start': this_node_index, 'end': item_node_index, 'properties': {'label': key}})\n",
    "          self.edge_index += 1\n",
    "      else:\n",
    "        if key in self.edge_attributes:\n",
    "          if not value == None:\n",
    "            self.add_edges.append( { 'start': this_node_index, 'end': value, 'properties': {'label': key}})\n",
    "          else:\n",
    "            print(\"****** Warning, null value %s *****\" % (key))\n",
    "        else:\n",
    "          properties[key] = value\n",
    "    properties['node_type'] = klass\n",
    "    properties['label'] = node[id_field]\n",
    "    self.nodes.append( { 'id': this_node_index, 'properties': properties } )\n",
    "    self.id_node_index_map[properties[id_field]] = this_node_index\n",
    "    return this_node_index\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON: {'timelineId': 'timeline_2', 'timelineEntry': {'entryId': 'entry_1', 'entryDescription': 'Main timeline', 'nextTimepointId': 'timepoint_1'}, 'timelineTimepoints': [{'timepointId': 'timepoint_1', 'nextTimepointId': 'timepoint_2', 'scheduledAt': {'timingId': 'timing_1', 'type': 'next', 'value': '0..30 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}}, {'timepointId': 'timepoint_2', 'nextTimepointId': 'timepoint_3', 'scheduledAt': {'timingId': 'timing_2', 'type': 'anchor', 'value': 'Day 1', 'relativeToFrom': None, 'window': None, 'relativeTo': None}}, {'timepointId': 'timepoint_3', 'nextTimepointId': 'timepoint_4', 'scheduledAt': {'timingId': 'timing_3', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}}, {'timepointId': 'timepoint_4', 'nextTimepointId': 'timepoint_5', 'scheduledAt': {'timingId': 'timing_4', 'type': 'anchor', 'value': 'Day 16', 'relativeToFrom': None, 'window': None, 'relativeTo': None}}, {'timepointId': 'timepoint_5', 'nextTimepointId': 'timepoint_6', 'scheduledAt': {'timingId': 'timing_5', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_4'}}, {'timepointId': 'timepoint_6', 'nextTimepointId': 'timepoint_7', 'scheduledAt': {'timingId': 'timing_6', 'type': 'after', 'value': '+30 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}}, {'timepointId': 'timepoint_7', 'nextTimepointId': 'timepoint_8', 'scheduledAt': {'timingId': 'timing_7', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_6'}}, {'timepointId': 'timepoint_8', 'nextTimepointId': 'timepoint_9', 'scheduledAt': {}}, {'timepointId': 'timepoint_9', 'nextTimepointId': 'timepoint_10', 'scheduledAt': {}}, {'timepointId': 'timepoint_10', 'nextTimepointId': 'timepoint_11', 'scheduledAt': {'timingId': 'timing_8', 'type': 'after', 'value': 'Within 30 days of last dose', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_9'}}, {'timepointId': 'timepoint_11', 'nextTimepointId': None, 'scheduledAt': {'timingId': 'timing_9', 'type': 'after', 'value': '+12 weeks', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_10'}, 'exit': {'exitId': 'exit_1'}}], 'timelineExit': {'exitId': 'exit_1'}}\n",
      "NODE: {'_type': 'Timeline', 'timelineId': 'timeline_2', 'timelineEntry': {'_type': 'Entry', 'entryId': 'entry_1', 'entryDescription': 'Main timeline', 'nextTimepointId': 'timepoint_1'}, 'timelineTimepoints': [{'_type': 'Timepoint', 'timepointId': 'timepoint_1', 'nextTimepointId': 'timepoint_2', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_1', 'type': 'next', 'value': '0..30 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}}, {'_type': 'Timepoint', 'timepointId': 'timepoint_2', 'nextTimepointId': 'timepoint_3', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_2', 'type': 'anchor', 'value': 'Day 1', 'relativeToFrom': None, 'window': None, 'relativeTo': None}}, {'_type': 'Timepoint', 'timepointId': 'timepoint_3', 'nextTimepointId': 'timepoint_4', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_3', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}}, {'_type': 'Timepoint', 'timepointId': 'timepoint_4', 'nextTimepointId': 'timepoint_5', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_4', 'type': 'anchor', 'value': 'Day 16', 'relativeToFrom': None, 'window': None, 'relativeTo': None}}, {'_type': 'Timepoint', 'timepointId': 'timepoint_5', 'nextTimepointId': 'timepoint_6', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_5', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_4'}}, {'_type': 'Timepoint', 'timepointId': 'timepoint_6', 'nextTimepointId': 'timepoint_7', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_6', 'type': 'after', 'value': '+30 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}}, {'_type': 'Timepoint', 'timepointId': 'timepoint_7', 'nextTimepointId': 'timepoint_8', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_7', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_6'}}, {'_type': 'Timepoint', 'timepointId': 'timepoint_8', 'nextTimepointId': 'timepoint_9', 'scheduledAt': {}}, {'_type': 'Timepoint', 'timepointId': 'timepoint_9', 'nextTimepointId': 'timepoint_10', 'scheduledAt': {}}, {'_type': 'Timepoint', 'timepointId': 'timepoint_10', 'nextTimepointId': 'timepoint_11', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_8', 'type': 'after', 'value': 'Within 30 days of last dose', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_9'}}, {'_type': 'Timepoint', 'timepointId': 'timepoint_11', 'nextTimepointId': None, 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_9', 'type': 'after', 'value': '+12 weeks', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_10'}, 'exit': {'_type': 'Exit', 'exitId': 'exit_1'}}], 'timelineExit': {'_type': 'Exit', 'exitId': 'exit_1'}}\n",
      "NODE: {'_type': 'Entry', 'entryId': 'entry_1', 'entryDescription': 'Main timeline', 'nextTimepointId': 'timepoint_1'}\n",
      "NODE: {'_type': 'Timepoint', 'timepointId': 'timepoint_1', 'nextTimepointId': 'timepoint_2', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_1', 'type': 'next', 'value': '0..30 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}}\n",
      "NODE: {'_type': 'Timing', 'timingId': 'timing_1', 'type': 'next', 'value': '0..30 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}\n",
      "NODE: {'_type': 'Timepoint', 'timepointId': 'timepoint_2', 'nextTimepointId': 'timepoint_3', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_2', 'type': 'anchor', 'value': 'Day 1', 'relativeToFrom': None, 'window': None, 'relativeTo': None}}\n",
      "NODE: {'_type': 'Timing', 'timingId': 'timing_2', 'type': 'anchor', 'value': 'Day 1', 'relativeToFrom': None, 'window': None, 'relativeTo': None}\n",
      "****** Warning, null value relativeTo *****\n",
      "NODE: {'_type': 'Timepoint', 'timepointId': 'timepoint_3', 'nextTimepointId': 'timepoint_4', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_3', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}}\n",
      "NODE: {'_type': 'Timing', 'timingId': 'timing_3', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}\n",
      "NODE: {'_type': 'Timepoint', 'timepointId': 'timepoint_4', 'nextTimepointId': 'timepoint_5', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_4', 'type': 'anchor', 'value': 'Day 16', 'relativeToFrom': None, 'window': None, 'relativeTo': None}}\n",
      "NODE: {'_type': 'Timing', 'timingId': 'timing_4', 'type': 'anchor', 'value': 'Day 16', 'relativeToFrom': None, 'window': None, 'relativeTo': None}\n",
      "****** Warning, null value relativeTo *****\n",
      "NODE: {'_type': 'Timepoint', 'timepointId': 'timepoint_5', 'nextTimepointId': 'timepoint_6', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_5', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_4'}}\n",
      "NODE: {'_type': 'Timing', 'timingId': 'timing_5', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_4'}\n",
      "NODE: {'_type': 'Timepoint', 'timepointId': 'timepoint_6', 'nextTimepointId': 'timepoint_7', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_6', 'type': 'after', 'value': '+30 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}}\n",
      "NODE: {'_type': 'Timing', 'timingId': 'timing_6', 'type': 'after', 'value': '+30 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}\n",
      "NODE: {'_type': 'Timepoint', 'timepointId': 'timepoint_7', 'nextTimepointId': 'timepoint_8', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_7', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_6'}}\n",
      "NODE: {'_type': 'Timing', 'timingId': 'timing_7', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_6'}\n",
      "NODE: {'_type': 'Timepoint', 'timepointId': 'timepoint_8', 'nextTimepointId': 'timepoint_9', 'scheduledAt': {}}\n",
      "NODE: {'_type': 'Timepoint', 'timepointId': 'timepoint_9', 'nextTimepointId': 'timepoint_10', 'scheduledAt': {}}\n",
      "NODE: {'_type': 'Timepoint', 'timepointId': 'timepoint_10', 'nextTimepointId': 'timepoint_11', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_8', 'type': 'after', 'value': 'Within 30 days of last dose', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_9'}}\n",
      "NODE: {'_type': 'Timing', 'timingId': 'timing_8', 'type': 'after', 'value': 'Within 30 days of last dose', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_9'}\n",
      "NODE: {'_type': 'Timepoint', 'timepointId': 'timepoint_11', 'nextTimepointId': None, 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_9', 'type': 'after', 'value': '+12 weeks', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_10'}, 'exit': {'_type': 'Exit', 'exitId': 'exit_1'}}\n",
      "****** Warning, null value nextTimepointId *****\n",
      "NODE: {'_type': 'Timing', 'timingId': 'timing_9', 'type': 'after', 'value': '+12 weeks', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_10'}\n",
      "NODE: {'_type': 'Exit', 'exitId': 'exit_1'}\n",
      "NODE: {'_type': 'Exit', 'exitId': 'exit_1'}\n",
      "ADD: [{'start': 2, 'end': 'timepoint_1', 'properties': {'label': 'nextTimepointId'}}, {'start': 3, 'end': 'timepoint_2', 'properties': {'label': 'nextTimepointId'}}, {'start': 4, 'end': 'timepoint_2', 'properties': {'label': 'relativeTo'}}, {'start': 5, 'end': 'timepoint_3', 'properties': {'label': 'nextTimepointId'}}, {'start': 7, 'end': 'timepoint_4', 'properties': {'label': 'nextTimepointId'}}, {'start': 8, 'end': 'timepoint_2', 'properties': {'label': 'relativeTo'}}, {'start': 9, 'end': 'timepoint_5', 'properties': {'label': 'nextTimepointId'}}, {'start': 11, 'end': 'timepoint_6', 'properties': {'label': 'nextTimepointId'}}, {'start': 12, 'end': 'timepoint_4', 'properties': {'label': 'relativeTo'}}, {'start': 13, 'end': 'timepoint_7', 'properties': {'label': 'nextTimepointId'}}, {'start': 14, 'end': 'timepoint_2', 'properties': {'label': 'relativeTo'}}, {'start': 15, 'end': 'timepoint_8', 'properties': {'label': 'nextTimepointId'}}, {'start': 16, 'end': 'timepoint_6', 'properties': {'label': 'relativeTo'}}, {'start': 17, 'end': 'timepoint_9', 'properties': {'label': 'nextTimepointId'}}, {'start': 18, 'end': 'timepoint_10', 'properties': {'label': 'nextTimepointId'}}, {'start': 19, 'end': 'timepoint_11', 'properties': {'label': 'nextTimepointId'}}, {'start': 20, 'end': 'timepoint_9', 'properties': {'label': 'relativeTo'}}, {'start': 22, 'end': 'timepoint_10', 'properties': {'label': 'relativeTo'}}]\n"
     ]
    }
   ],
   "source": [
    "notebook_path = os.path.abspath(\"notebook.ipynb\")\n",
    "file_path = os.path.join(os.path.dirname(notebook_path), \"source_data/berber_1_v2.xlsx\")\n",
    "#file_path = os.path.join(os.path.dirname(notebook_path), \"source_data/Roche Phase 3 NCT04320615.xlsx\")\n",
    "df = pd.read_excel(file_path, header=None)\n",
    "df = df.fillna(method='ffill', axis=1)\n",
    "cycles = extract_cycles(df)\n",
    "timepoints = extract_timepoints(df)\n",
    "encounters = extract_encounters(df)\n",
    "activities = extract_activities_and_bcs(df)\n",
    "tp_activities = extract_timepoint_activities_map(df, timepoints, activities['activities'], activities['row_activities_map'])\n",
    "#print(\"CYCLES\", cycles)\n",
    "#print(\"TIMEPOINTS\", timepoints)\n",
    "#print(\"ENCOUNTERS\", encounters)\n",
    "#print(\"ACTIVITIES\", activities)\n",
    "#print(\"TP ACTIVITIES\", tp_activities)\n",
    "\n",
    "x = DDFJson()\n",
    "node = x.process_timepoints(timepoints)\n",
    "print(\"JSON:\", x.export(node))\n",
    "\n",
    "y = DDFVisual()\n",
    "nodes, edges = y.draw(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6940d94c89ac444bb380d5dea76bfc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='500px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def custom_node_color(index: int, node: dict):\n",
    "  if 'node_type' in node['properties']:\n",
    "    if node['properties']['node_type'] == 'Entry':\n",
    "      return 'black'\n",
    "    elif node['properties']['node_type'] == 'Exit':\n",
    "      return 'black'\n",
    "    elif node['properties']['node_type'] == 'Timeline':\n",
    "      return 'blue'\n",
    "    elif node['properties']['node_type'] == 'Timepoint':\n",
    "      return 'black'\n",
    "    else:\n",
    "      return 'white'\n",
    "  else: \n",
    "    return 'white'\n",
    "\n",
    "def custom_node_style(index: int, node: dict):\n",
    "  if 'node_type' in node['properties']:\n",
    "    if node['properties']['node_type'] == 'Entry' or node['properties']['node_type'] == 'Exit':\n",
    "      return {'image': 'https://raw.githubusercontent.com/data4knowledge/timepoints/main/images/pill_black.svg'}\n",
    "    elif node['properties']['node_type'] == 'Timeline':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    elif node['properties']['node_type'] == 'Timepoint':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    else:\n",
    "      return { 'shape': 'ellipse' }\n",
    "  else: \n",
    "    return { 'shape': 'ellipse' }\n",
    "\n",
    "widget = GraphWidget()\n",
    "widget.orthogonal_layout()\n",
    "widget.set_directed(True)\n",
    "\n",
    "widget.set_nodes(nodes)\n",
    "widget.set_edges(edges)\n",
    "widget.set_node_color_mapping(custom_node_color)\n",
    "widget.set_node_styles_mapping(custom_node_style)\n",
    "widget"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
