{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: yfiles_jupyter_graphs in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.4.3)\n",
      "Requirement already satisfied: ipywidgets>=7.6.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from yfiles_jupyter_graphs) (8.0.4)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (6.20.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (8.8.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (3.0.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.8.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (4.0.5)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (25.0.0)\n",
      "Requirement already satisfied: psutil in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.9.4)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (6.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.6.5)\n",
      "Requirement already satisfied: appnope in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.1.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (7.4.8)\n",
      "Requirement already satisfied: nest-asyncio in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.5.6)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (21.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.18.2)\n",
      "Requirement already satisfied: decorator in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.13.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (3.0.36)\n",
      "Requirement already satisfied: backcall in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.1.3)\n",
      "Requirement already satisfied: entrypoints in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (3.0.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.2.1)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.16.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.6.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install openpyxl\n",
    "%pip install yfiles_jupyter_graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from yfiles_jupyter_graphs import GraphWidget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_ROW = 0\n",
    "CYCLE_ROW = 1\n",
    "CYCLE_START_ROW = 2\n",
    "CYCLE_PERIOD_ROW = 3\n",
    "CYCLE_END_RULE_ROW = 4\n",
    "TIMING_ROW = 5\n",
    "VISIT_LABEL_ROW = 6\n",
    "VISIT_WINDOW_ROW = 7\n",
    "\n",
    "HEADER_ROW = 8\n",
    "FIRST_ACTIVITY_ROW = 9\n",
    "\n",
    "ACTIVITY_COL = 0\n",
    "CHILD_ACTIVITY_COL = 1\n",
    "BC_COL = 2\n",
    "PROFILE_COL = 3\n",
    "FIRST_VISIT_COL = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cycle_cell(df, row_index, col_index):\n",
    "  is_null = pd.isnull(df.iloc[row_index, col_index])\n",
    "  if is_null:\n",
    "    return \"\", True\n",
    "  else:\n",
    "    value = str(df.iloc[row_index, col_index])\n",
    "    if value.upper() == \"-\":\n",
    "      return \"\", True\n",
    "    else:\n",
    "      return value, False\n",
    "\n",
    "def previous_index(index):\n",
    "  if index == 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return index - 1\n",
    "\n",
    "def build_cycle_record(df, index, col_index, cycle):\n",
    "  cycle_start_index = index\n",
    "  cycle_start, is_null = get_cycle_cell(df, CYCLE_START_ROW, col_index)\n",
    "  cycle_period, is_null = get_cycle_cell(df, CYCLE_PERIOD_ROW, col_index)\n",
    "  cycle_end_rule, is_null = get_cycle_cell(df, CYCLE_END_RULE_ROW, col_index)\n",
    "  return { \n",
    "    'start_index': cycle_start_index, \n",
    "    'cycle': cycle, \n",
    "    'start': cycle_start, \n",
    "    'period': cycle_period, \n",
    "    'end_rule': cycle_end_rule \n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cycles(df):\n",
    "  cycles = []\n",
    "  timepoint_index = -1\n",
    "  cycle_start_index = None\n",
    "  in_cycle = False\n",
    "  prev_cycle = None\n",
    "  for col_index in range(df.shape[1]):\n",
    "    if col_index >= FIRST_VISIT_COL:\n",
    "      timepoint_index += 1\n",
    "      cycle, cycle_is_null = get_cycle_cell(df, CYCLE_ROW, col_index)\n",
    "      if cycle_is_null:\n",
    "        if in_cycle:\n",
    "          cycle_record['end_index'] = previous_index(timepoint_index)\n",
    "          cycles.append(cycle_record)\n",
    "          in_cycle = False\n",
    "        else:\n",
    "          pass # Do nothing\n",
    "      else:\n",
    "        cycle = str(cycle)\n",
    "        if not in_cycle:\n",
    "          in_cycle = True\n",
    "          cycle_record = build_cycle_record(df, timepoint_index, col_index, cycle)\n",
    "        elif prev_cycle == cycle:\n",
    "          pass # Do nothing\n",
    "        else:\n",
    "          cycle_record['end_index'] = previous_index(timepoint_index)\n",
    "          cycles.append(cycle_record)\n",
    "          cycle_record = build_cycle_record(df, timepoint_index, col_index, cycle)\n",
    "      prev_cycle = cycle\n",
    "  return cycles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timing_cell(df, row_index, col_index):\n",
    "  is_null = pd.isnull(df.iloc[row_index, col_index])\n",
    "  if is_null:\n",
    "    return \"\", True\n",
    "  else:\n",
    "    return df.iloc[row_index, col_index], False\n",
    "\n",
    "def get_relative_ref(part):\n",
    "  if len(part) > 1:\n",
    "    return int(part[1:])\n",
    "  else:\n",
    "    return 1\n",
    "\n",
    "def get_timing_type(df, col_index):\n",
    "  timing_type = \"\"\n",
    "  rel_ref = 0\n",
    "  timing_value = \"\"\n",
    "  timing_info, timing_info_is_null = get_timing_cell(df, TIMING_ROW, col_index)\n",
    "  if not timing_info_is_null:\n",
    "    timing_parts = timing_info.split(\":\")\n",
    "    if timing_parts[0].upper()[0] == \"A\":\n",
    "      timing_type = \"anchor\"\n",
    "      rel_ref = 0\n",
    "    if timing_parts[0].upper()[0] == \"P\":\n",
    "      timing_type = \"previous\"\n",
    "      rel_ref = get_relative_ref(timing_parts[0]) * -1\n",
    "    elif timing_parts[0].upper()[0] == \"N\":\n",
    "      timing_type = \"next\"\n",
    "      rel_ref = get_relative_ref(timing_parts[0])\n",
    "    elif timing_parts[0].upper()[0] == \"C\":\n",
    "      timing_type = \"cycle start\"\n",
    "      rel_ref = get_relative_ref(timing_parts[0])\n",
    "    if len(timing_parts) == 2:\n",
    "      timing_value = timing_parts[1].strip()\n",
    "  #print(\"TIMING: col_index (%s) - FIRST_VISIT_COL (%s) + rel_ref (%s)\" % (col_index, FIRST_VISIT_COL, rel_ref))\n",
    "  return { 'type': timing_type, 'ref': col_index - FIRST_VISIT_COL + rel_ref, 'value': timing_value }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timepoints(df):\n",
    "  timepoints = []\n",
    "  for col_index in range(df.shape[1]):\n",
    "    if col_index >= FIRST_VISIT_COL:\n",
    "      record = get_timing_type(df, col_index)\n",
    "      timepoints.append(record)\n",
    "  return timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encounter_cell(df, row_index, col_index):\n",
    "  is_null = pd.isnull(df.iloc[row_index, col_index])\n",
    "  if is_null:\n",
    "    return \"\", True\n",
    "  else:\n",
    "    return df.iloc[row_index, col_index], False\n",
    "\n",
    "def get_encounter_details(df, col_index):\n",
    "  label = \"\"\n",
    "  window = \"\"\n",
    "  label, label_is_null = get_encounter_cell(df, VISIT_LABEL_ROW, col_index)\n",
    "  window, window_is_null = get_encounter_cell(df, VISIT_WINDOW_ROW, col_index)\n",
    "  return { 'label': label, 'window': window }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_encounters(df):\n",
    "  encounters = []\n",
    "  for col_index in range(df.shape[1]):\n",
    "    if col_index >= FIRST_VISIT_COL:\n",
    "      record = get_encounter_details(df, col_index)\n",
    "      encounters.append(record)\n",
    "  return encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_cell(df, row_index, col_index):\n",
    "  is_null = pd.isnull(df.iloc[row_index, col_index])\n",
    "  if is_null:\n",
    "    return \"\", True\n",
    "  else:\n",
    "    value = df.iloc[row_index, col_index]\n",
    "    if value == '-':\n",
    "      return \"\", True\n",
    "    else:\n",
    "      return df.iloc[row_index, col_index], False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDFVisual():\n",
    "\n",
    "  def __init__(self):\n",
    "    self.nodes = []\n",
    "    self.edges = []\n",
    "    self.add_edges = []\n",
    "    self.node_index = 1\n",
    "    self.edge_index = 1\n",
    "    self.id_node_index_map = {}\n",
    "    self.type_id_field_map = { \n",
    "      'Entry': 'entryId',\n",
    "      'Exit': 'exitId',\n",
    "      'Timeline': 'timelineId',\n",
    "      'Timepoint': 'timepointId',\n",
    "      'Timing': 'timingId',\n",
    "      'Condition': 'timepointId',\n",
    "      'CycleStart': 'cycleStartId',\n",
    "      'StudyDesign': 'studyDesignId',\n",
    "      'Activity': 'activityId',\n",
    "      'Encounter': 'encounterId'\n",
    "    }\n",
    "    self.edge_attributes = [\n",
    "      'relativeTo',\n",
    "      'nextTimepointId',\n",
    "      'cycleId',\n",
    "      'timepointActivityIds',\n",
    "      'timepointEncounterId'\n",
    "    ]\n",
    "    \n",
    "  def get_id_field_and_klass(self, node):\n",
    "    klass = node['_type']\n",
    "    return self.type_id_field_map[klass], klass\n",
    "\n",
    "  def draw(self, json):\n",
    "    self.process_node(json)\n",
    "    for edge in self.add_edges:\n",
    "      if edge['end'] in self.id_node_index_map:\n",
    "        edge['id'] = self.edge_index\n",
    "        edge['end'] = self.id_node_index_map[edge['end']]\n",
    "        self.edges.append(edge)\n",
    "        self.edge_index += 1\n",
    "      else:\n",
    "        print(\"***** %s -edge-> %s *****\" % (edge['start'], edge['end']))\n",
    "    return self.nodes, self.edges\n",
    "  \n",
    "  def process_node(self, node):\n",
    "    if type(node) == list:\n",
    "      result = []\n",
    "      for item in node:\n",
    "        indexes = self.process_node(item)\n",
    "        result = result + indexes\n",
    "      return result\n",
    "    elif type(node) == dict:\n",
    "      if node == {}:\n",
    "        return []\n",
    "      properties = {}\n",
    "      id_field, klass = self.get_id_field_and_klass(node)\n",
    "      if node[id_field] in self.id_node_index_map:\n",
    "        return [self.id_node_index_map[node[id_field]]]\n",
    "      this_node_index = self.node_index\n",
    "      self.node_index += 1\n",
    "      for key, value in node.items():\n",
    "        if key in self.edge_attributes:\n",
    "          if type(value) == list:\n",
    "            for item in value:\n",
    "              self.add_edges.append( { 'start': this_node_index, 'end': item, 'properties': {'label': key}})\n",
    "          else:\n",
    "            self.add_edges.append( { 'start': this_node_index, 'end': value, 'properties': {'label': key}})\n",
    "        else:\n",
    "          indexes = self.process_node(value)\n",
    "          if indexes == []:\n",
    "            properties[key] = value\n",
    "          else:\n",
    "            for index in indexes:\n",
    "              self.edges.append( {'id': self.edge_index, 'start': this_node_index, 'end': index, 'properties': {'label': key}})\n",
    "              self.edge_index += 1\n",
    "      properties['node_type'] = klass\n",
    "      properties['label'] = node[id_field]\n",
    "      self.nodes.append({ 'id': this_node_index, 'properties': properties })\n",
    "      self.id_node_index_map[properties[id_field]] = this_node_index\n",
    "      return [this_node_index]\n",
    "    else:\n",
    "      return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activities_and_bcs(df):\n",
    "  activities = []\n",
    "  activities_bc_map = {}\n",
    "  row_activities_map = []\n",
    "  prev_activity = None\n",
    "  for row_index, col_def in df.iterrows():\n",
    "    if row_index >= FIRST_ACTIVITY_ROW:\n",
    "      activity, activity_is_null = get_activity_cell(df, row_index, CHILD_ACTIVITY_COL)\n",
    "      if activity_is_null:\n",
    "        if not prev_activity == None:\n",
    "          row_activities_map.append(prev_activity)\n",
    "          activity = prev_activity\n",
    "      else:\n",
    "        activities.append(activity)\n",
    "        row_activities_map.append(activity)\n",
    "      prev_activity = activity\n",
    "      bc, bc_is_null = get_activity_cell(df, row_index, BC_COL)\n",
    "      if not bc_is_null:\n",
    "        if not activity in activities_bc_map:\n",
    "          activities_bc_map[activity] = { 'bc': [] }  \n",
    "        activities_bc_map[activity]['bc'].append(bc)\n",
    "  return { \n",
    "    'activities': activities,\n",
    "    'activity_bc_map': activities_bc_map,\n",
    "    'row_activities_map': row_activities_map\n",
    "  }\n",
    "\n",
    "def extract_timepoint_activities_map(df, timepoints, activities, row_activities_map):\n",
    "  timepoint_activity_map = []\n",
    "  activity_dict = {}\n",
    "  for activity in activities:\n",
    "    activity_dict[activity] = False\n",
    "  for tp in timepoints:\n",
    "    timepoint_activity_map.append(dict(activity_dict))\n",
    "  for index in range(df.shape[1]):\n",
    "    if index >= FIRST_VISIT_COL:\n",
    "      column = df.iloc[:, index]\n",
    "      row = 0\n",
    "      for col in column:\n",
    "        if row >= FIRST_ACTIVITY_ROW:\n",
    "          if not pd.isnull(col):\n",
    "            if col.upper() == \"X\":\n",
    "              activity = row_activities_map[row - FIRST_ACTIVITY_ROW]\n",
    "              tp_index = index - FIRST_VISIT_COL\n",
    "              timepoint_activity_map[tp_index][activity] = True\n",
    "        row += 1\n",
    "  return timepoint_activity_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDFJson():\n",
    "  \n",
    "  def __init__(self):\n",
    "    self.id_index = { 'entry': 0, 'exit': 0, 'timepoint': 0, 'timeline': 0, 'timing': 0, 'study_design': 0, 'activity': 0, 'encounter': 0 }\n",
    "    self.dicts = {}\n",
    "\n",
    "  def increment_index(self, name):\n",
    "    self.id_index[name] += 1\n",
    "\n",
    "  def build_id(self, name):\n",
    "    self.increment_index(name)\n",
    "    return \"%s_%s\" % (name, self.id_index[name])\n",
    "\n",
    "  def add_entry(self, description, timepoint_id):\n",
    "    id = self.build_id('entry')\n",
    "    result = { '_type': 'Entry', 'entryId': id, 'entryDescription': description, 'nextTimepointId': timepoint_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_exit(self):\n",
    "    id = self.build_id('exit')\n",
    "    result = { '_type': 'Exit', 'exitId': id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_timepoint(self, previous_timepoint_id, timing, activities, encounter):\n",
    "    id = self.build_id('timepoint')\n",
    "    result = { '_type': 'Timepoint', 'timepointId': id, 'nextTimepointId': None, 'scheduledAt': timing, 'timepointActivityIds': activities, 'timepointEncounterId': encounter }\n",
    "    self.dicts[id] = result\n",
    "    if not previous_timepoint_id == None:\n",
    "      self.dicts[previous_timepoint_id]['nextTimepointId'] = id\n",
    "    return result\n",
    "\n",
    "  def add_previous_timing(self, value, relative_to_from, window, to_id):\n",
    "    id = self.build_id('timing')\n",
    "    result = { '_type': 'Timing', 'timingId': id, 'type': \"after\", 'value': value, 'relativeToFrom': relative_to_from, 'window': window, 'relativeTo': to_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_next_timing(self, value, relative_to_from, window, to_id):\n",
    "    id = self.build_id('timing')\n",
    "    result = { '_type': 'Timing', 'timingId': id, 'type': \"next\", 'value': value, 'relativeToFrom': relative_to_from, 'window': window, 'relativeTo': to_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_anchor_timing(self, value, cycle=\"\"):\n",
    "    id = self.build_id('timing')\n",
    "    result = { '_type': 'Timing', 'timingId': id, 'type': \"anchor\", 'value': value, 'cycle': cycle, 'relativeToFrom': None, 'window': None, 'relativeTo': None }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_condition_timing(self, value, to_id):\n",
    "    id = self.build_id('timing')\n",
    "    result = { '_type': 'Condition', 'conditionId': id, 'type': \"condition\", 'value': value, 'relativeToFrom': None, 'window': None, 'relativeTo': to_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_cycle_start_timing(self, value):\n",
    "    id = self.build_id('timing')\n",
    "    result = { '_type': 'CycleStart', 'cycleStartId': id, 'type': \"cycle start\", 'value': value, 'relativeToFrom': None, 'window': None, 'relativeTo': None }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_timeline(self, entry, timepoints, exit):\n",
    "    id = self.build_id('timeline')\n",
    "    result = { '_type': 'Timeline', 'timelineId': id, 'timelineEntry': entry, 'timelineTimepoints': timepoints, 'timelineExit': exit }\n",
    "    self.dicts['id'] = result\n",
    "    return result\n",
    "  \n",
    "  def add_activity(self, name, description, conditional=False, conditional_reason=\"\"):\n",
    "    id = self.build_id('activity')\n",
    "    result = { '_type': 'Activity', 'activityId': id, 'activityName': name, 'activityDescription': description, 'activityIsConditional': conditional, 'activityConditionalReason': conditional_reason }\n",
    "    self.dicts['id'] = result\n",
    "    return result\n",
    "\n",
    "  def add_encounter(self, name, description, enc_type, env_setting, contact_modes):\n",
    "    id = self.build_id('encounter')\n",
    "    result = { '_type': 'Encounter', 'encounterId': id, 'encounterName': name, 'encounterDescription': description, 'encounterType': enc_type, 'encounterEnvironmentalSetting': env_setting, 'encounterContactMode': contact_modes }\n",
    "    self.dicts['id'] = result\n",
    "    return result\n",
    "\n",
    "  def add_study_design(self, intent, types, model, therapeutic_areas, cells, indications, objectives, populations, interventions, workflows, estimands, encounters, activities):\n",
    "    id = self.build_id('study_design')\n",
    "    result = { '_type': 'StudyDesign', 'studyDesignId': id, 'studyWorkflows': workflows, 'activities': activities, 'encounters': encounters }\n",
    "    self.dicts['id'] = result\n",
    "    return result\n",
    "    \n",
    "  def process_timepoints(self, timepoints, cycles, activities, tp_activities, encounters):\n",
    "    tps = []\n",
    "    acts = []\n",
    "    encs = []\n",
    "    acts_map = {}\n",
    "    timing = []\n",
    "    cycle_offset = 0\n",
    "    for index, timepoint in enumerate(timepoints):\n",
    "      timepoint['activity_index'] = index\n",
    "      timepoint['encounter_index'] = index\n",
    "    for cycle in cycles:\n",
    "      start_index = cycle['start_index'] + cycle_offset\n",
    "      timepoints.insert(start_index, { 'type': 'anchor', 'ref': 0, 'value': cycle['start'], 'activity_index': None, 'encounter_index': None, 'cycle': cycle['cycle'] })\n",
    "      cycle_offset += 1\n",
    "      end_index = cycle['end_index'] + cycle_offset + 1\n",
    "      timepoints.insert(end_index, { 'type': 'previous', 'ref': end_index - 1, 'value': cycle['period'], 'activity_index': None, 'encounter_index': None, 'cycle': None })\n",
    "      cycle_offset += 1\n",
    "      end_index = cycle['end_index'] + cycle_offset + 1\n",
    "      timepoints.insert(end_index, { 'type': 'condition', 'ref': start_index , 'value': cycle['end_rule'], 'activity_index': None, 'encounter_index': None, 'cycle': None })\n",
    "      cycle_offset += 1\n",
    "    previous_tp_id = None\n",
    "    for activity in activities['activities']:\n",
    "      acts.append(self.add_activity(activity, activity))\n",
    "      acts_map[activity] = acts[-1]['activityId']\n",
    "    for encounter in encounters:\n",
    "      encs.append(self.add_encounter(encounter['label'], encounter['label'], None, None, []))\n",
    "    for timepoint in timepoints:\n",
    "      activity_ids = []\n",
    "      encounter_ids = None\n",
    "      if not timepoint['activity_index'] == None:\n",
    "        source = tp_activities[timepoint['activity_index']]\n",
    "        for k, v in source.items():\n",
    "          if v:\n",
    "            activity_ids.append(acts_map[k])\n",
    "      print(\"TP:\", timepoint)\n",
    "      if not timepoint['encounter_index'] == None:\n",
    "        encounter_id = encs[timepoint['encounter_index']]['encounterId']\n",
    "      tps.append(self.add_timepoint(previous_tp_id, None, activity_ids, encounter_id))\n",
    "      previous_tp_id = tps[-1]['timepointId']\n",
    "    for index, timepoint in enumerate(timepoints):\n",
    "      if timepoint['type'] == 'condition':\n",
    "        tps[index]['cycleId'] = tps[timepoint['ref']]['timepointId']\n",
    "        tps[index]['_type'] = 'Condition'\n",
    "    for timepoint in timepoints:\n",
    "      if timepoint['type'] == 'next':\n",
    "        timing.append(self.add_next_timing(timepoint['value'], 'StartToStart', None, tps[timepoint['ref']]['timepointId']))\n",
    "      elif timepoint['type'] == 'previous':\n",
    "        timing.append(self.add_previous_timing(timepoint['value'], 'StartToStart', None, tps[timepoint['ref']]['timepointId']))\n",
    "      elif timepoint['type'] == 'anchor':\n",
    "        timing.append(self.add_anchor_timing(timepoint['value'], timepoint['cycle']))\n",
    "      elif timepoint['type'] == 'condition':\n",
    "        #timing.append(self.add_condition_timing(timepoint['value']))\n",
    "        timing.append({})\n",
    "      elif timepoint['type'] == 'cycle start':\n",
    "        timing.append(self.add_cycle_start_timing(timepoint['value']))\n",
    "      elif timepoint['type'] == '':\n",
    "        timing.append({})\n",
    "    for index, tp in enumerate(tps):\n",
    "      tp['scheduledAt'] = timing[index]\n",
    "    entry = self.add_entry('Main timeline', tps[0]['timepointId'])\n",
    "    exit = self.add_exit()\n",
    "    tps[-1]['exit'] = exit\n",
    "    timeline = self.add_timeline(entry, tps, exit)\n",
    "    return self.add_study_design(\n",
    "      intent=None, \n",
    "      types=[], \n",
    "      model=None, \n",
    "      therapeutic_areas=[], \n",
    "      cells=[], \n",
    "      indications=[], \n",
    "      objectives=[], \n",
    "      populations=[], \n",
    "      interventions=[], \n",
    "      workflows=[timeline],\n",
    "      estimands=[], \n",
    "      encounters=encs, \n",
    "      activities=acts\n",
    "    ) \n",
    "  \n",
    "  def export(self, node):\n",
    "    return self.export_node(node)\n",
    "\n",
    "  def export_node(self, node):\n",
    "    if type(node) == list:\n",
    "      result = []\n",
    "      for item in node:\n",
    "        result.append(self.export_node(item))\n",
    "      return result\n",
    "    elif type(node) == dict:\n",
    "      result = {}\n",
    "      for key, value in node.items():\n",
    "        if key.startswith('_'):\n",
    "          continue\n",
    "        result[key] = self.export_node(value)\n",
    "      return result\n",
    "    else:\n",
    "      return node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_file(data, filename):\n",
    "  with open('source_data/%s.json' % (filename), 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(data, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: {'type': 'next', 'ref': 1, 'value': '0..30 Days', 'activity_index': 0, 'encounter_index': 0}\n",
      "TP: {'type': 'anchor', 'ref': 0, 'value': 'Day 1', 'activity_index': None, 'encounter_index': None, 'cycle': '1'}\n",
      "TP: {'type': 'cycle start', 'ref': 2, 'value': '', 'activity_index': 1, 'encounter_index': 1}\n",
      "TP: {'type': 'previous', 'ref': 1, 'value': '+14 Days', 'activity_index': 2, 'encounter_index': 2}\n",
      "TP: {'type': 'previous', 'ref': 3, 'value': '15 Days', 'activity_index': None, 'encounter_index': None, 'cycle': None}\n",
      "TP: {'type': 'condition', 'ref': 1, 'value': '', 'activity_index': None, 'encounter_index': None, 'cycle': None}\n",
      "TP: {'type': 'anchor', 'ref': 0, 'value': 'Day 16', 'activity_index': None, 'encounter_index': None, 'cycle': '2'}\n",
      "TP: {'type': 'cycle start', 'ref': 4, 'value': '', 'activity_index': 3, 'encounter_index': 3}\n",
      "TP: {'type': 'previous', 'ref': 3, 'value': '+14 Days', 'activity_index': 4, 'encounter_index': 4}\n",
      "TP: {'type': 'previous', 'ref': 8, 'value': '15 Days', 'activity_index': None, 'encounter_index': None, 'cycle': None}\n",
      "TP: {'type': 'condition', 'ref': 6, 'value': '', 'activity_index': None, 'encounter_index': None, 'cycle': None}\n",
      "TP: {'type': 'anchor', 'ref': 0, 'value': 'Day 31', 'activity_index': None, 'encounter_index': None, 'cycle': '3'}\n",
      "TP: {'type': 'cycle start', 'ref': 6, 'value': '', 'activity_index': 5, 'encounter_index': 5}\n",
      "TP: {'type': 'previous', 'ref': 5, 'value': '+14 Days', 'activity_index': 6, 'encounter_index': 6}\n",
      "TP: {'type': 'previous', 'ref': 13, 'value': '15 Days', 'activity_index': None, 'encounter_index': None, 'cycle': None}\n",
      "TP: {'type': 'condition', 'ref': 11, 'value': '', 'activity_index': None, 'encounter_index': None, 'cycle': None}\n",
      "TP: {'type': 'anchor', 'ref': 0, 'value': 'Day 46', 'activity_index': None, 'encounter_index': None, 'cycle': '4..12'}\n",
      "TP: {'type': 'cycle start', 'ref': 8, 'value': '', 'activity_index': 7, 'encounter_index': 7}\n",
      "TP: {'type': 'previous', 'ref': 17, 'value': '15 Days', 'activity_index': None, 'encounter_index': None, 'cycle': None}\n",
      "TP: {'type': 'condition', 'ref': 16, 'value': '', 'activity_index': None, 'encounter_index': None, 'cycle': None}\n",
      "TP: {'type': 'anchor', 'ref': 0, 'value': 'Day 211', 'activity_index': None, 'encounter_index': None, 'cycle': '13 .. N step 3'}\n",
      "TP: {'type': 'cycle start', 'ref': 9, 'value': '', 'activity_index': 8, 'encounter_index': 8}\n",
      "TP: {'type': 'previous', 'ref': 21, 'value': '15 Days', 'activity_index': None, 'encounter_index': None, 'cycle': None}\n",
      "TP: {'type': 'condition', 'ref': 20, 'value': 'Disease Progresssion', 'activity_index': None, 'encounter_index': None, 'cycle': None}\n",
      "TP: {'type': 'previous', 'ref': 8, 'value': 'Within 30 days of last dose', 'activity_index': 9, 'encounter_index': 9}\n",
      "TP: {'type': 'previous', 'ref': 9, 'value': '+12 weeks', 'activity_index': 10, 'encounter_index': 10}\n",
      "***** 7 -edge-> None *****\n",
      "***** 9 -edge-> None *****\n",
      "***** 16 -edge-> None *****\n",
      "***** 18 -edge-> None *****\n",
      "***** 25 -edge-> None *****\n",
      "***** 27 -edge-> None *****\n",
      "***** 34 -edge-> None *****\n",
      "***** 36 -edge-> None *****\n",
      "***** 41 -edge-> None *****\n",
      "***** 43 -edge-> None *****\n",
      "***** 49 -edge-> None *****\n"
     ]
    }
   ],
   "source": [
    "notebook_path = os.path.abspath(\"notebook.ipynb\")\n",
    "file_path = os.path.join(os.path.dirname(notebook_path), \"source_data/berber_1_v2.xlsx\")\n",
    "#file_path = os.path.join(os.path.dirname(notebook_path), \"source_data/Roche Phase 3 NCT04320615.xlsx\")\n",
    "df = pd.read_excel(file_path, header=None)\n",
    "df = df.fillna(method='ffill', axis=1)\n",
    "cycles = extract_cycles(df)\n",
    "timepoints = extract_timepoints(df)\n",
    "encounters = extract_encounters(df)\n",
    "activities = extract_activities_and_bcs(df)\n",
    "tp_activities = extract_timepoint_activities_map(df, timepoints, activities['activities'], activities['row_activities_map'])\n",
    "#print(\"CYCLES\", cycles)\n",
    "#print(\"TIMEPOINTS\", timepoints)\n",
    "#print(\"ENCOUNTERS\", encounters)\n",
    "#print(\"ACTIVITIES\", activities)\n",
    "#print(\"TP ACTIVITIES\", tp_activities)\n",
    "\n",
    "x = DDFJson()\n",
    "node = x.process_timepoints(timepoints, cycles, activities, tp_activities, encounters)\n",
    "data = x.export(node)\n",
    "#print(\"\")\n",
    "#print(\"\")\n",
    "#print(json.dumps(data, indent=4))\n",
    "save_as_file(data, \"berber_1_v2\")\n",
    "\n",
    "y = DDFVisual()\n",
    "nodes, edges = y.draw(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8798ac56d45644db9e96ddcdf134f4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='500px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def custom_node_color(index: int, node: dict):\n",
    "  if 'node_type' in node['properties']:\n",
    "    if node['properties']['node_type'] == 'Entry':\n",
    "      return 'black'\n",
    "    elif node['properties']['node_type'] == 'Exit':\n",
    "      return 'black'\n",
    "    elif node['properties']['node_type'] == 'Timeline':\n",
    "      return '#3F6AFC'\n",
    "    elif node['properties']['node_type'] == 'Condition':\n",
    "      return '#ABB2B9'\n",
    "    elif node['properties']['node_type'] == 'CycleStart':\n",
    "      return '#3F6AFC'\n",
    "    elif node['properties']['node_type'] == 'Timing':\n",
    "      return '#6495ED'\n",
    "    elif node['properties']['node_type'] == 'Timepoint':\n",
    "      return '#ABB2B9'\n",
    "    elif node['properties']['node_type'] == 'Activity':\n",
    "      return '#1BA62F'\n",
    "    elif node['properties']['node_type'] == 'Encounter':\n",
    "      return '#E53F2F'\n",
    "    elif node['properties']['node_type'] == 'StudyDesign':\n",
    "      return '#1BA62F'\n",
    "    else:\n",
    "      return 'white'\n",
    "  else: \n",
    "    return 'white'\n",
    "\n",
    "def custom_node_style(index: int, node: dict):\n",
    "  if 'node_type' in node['properties']:\n",
    "    if node['properties']['node_type'] == 'Entry' or node['properties']['node_type'] == 'Exit':\n",
    "      return {'image': 'https://raw.githubusercontent.com/data4knowledge/timepoints/main/images/pill_black.svg'}\n",
    "    elif node['properties']['node_type'] == 'Timeline':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    elif node['properties']['node_type'] == 'Timing':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    elif node['properties']['node_type'] == 'Condition':\n",
    "      return { 'shape': 'diamond' }\n",
    "    elif node['properties']['node_type'] == 'CycleStart':\n",
    "      return { 'shape': 'hexagon2' }\n",
    "    elif node['properties']['node_type'] == 'Timepoint':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    elif node['properties']['node_type'] == 'Activity':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    else:\n",
    "      return { 'shape': 'ellipse' }\n",
    "  else: \n",
    "    return { 'shape': 'ellipse' }\n",
    "\n",
    "widget = GraphWidget()\n",
    "widget.orthogonal_layout()\n",
    "widget.set_directed(True)\n",
    "\n",
    "widget.set_nodes(nodes)\n",
    "widget.set_edges(edges)\n",
    "widget.set_node_color_mapping(custom_node_color)\n",
    "widget.set_node_styles_mapping(custom_node_style)\n",
    "widget"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
