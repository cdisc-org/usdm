{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.10/site-packages (23.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./.venv/lib/python3.10/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in ./.venv/lib/python3.10/site-packages (3.1.1)\n",
      "Requirement already satisfied: et-xmlfile in ./.venv/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: yfiles_jupyter_graphs in ./.venv/lib/python3.10/site-packages (1.4.3)\n",
      "Requirement already satisfied: ipywidgets>=7.6.0 in ./.venv/lib/python3.10/site-packages (from yfiles_jupyter_graphs) (8.0.4)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in ./.venv/lib/python3.10/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (4.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in ./.venv/lib/python3.10/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (3.0.5)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.10/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (8.10.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in ./.venv/lib/python3.10/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (6.21.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.10/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.9.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.1.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.6.6)\n",
      "Requirement already satisfied: tornado>=6.1 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (6.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (23.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.1.6)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.9.4)\n",
      "Requirement already satisfied: pyzmq>=20 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (25.0.0)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.5.6)\n",
      "Requirement already satisfied: appnope in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.1.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (8.0.3)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.1.1)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (3.0.36)\n",
      "Requirement already satisfied: pickleshare in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.18.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.14.0)\n",
      "Requirement already satisfied: backcall in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (3.0.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.2.6)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.2.0)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.10/site-packages (8.0.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.10/site-packages (from ipywidgets) (8.10.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in ./.venv/lib/python3.10/site-packages (from ipywidgets) (4.0.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in ./.venv/lib/python3.10/site-packages (from ipywidgets) (6.21.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in ./.venv/lib/python3.10/site-packages (from ipywidgets) (3.0.5)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (8.0.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.6)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (23.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.4)\n",
      "Requirement already satisfied: pyzmq>=20 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (25.0.0)\n",
      "Requirement already satisfied: appnope in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install pandas\n",
    "%pip install openpyxl\n",
    "%pip install yfiles_jupyter_graphs\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import traceback\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDFJson():\n",
    "  \n",
    "  def __init__(self):\n",
    "    self.id_index = { \n",
    "      'code': 0, \n",
    "      'organisation': 0,\n",
    "      'study_identifier': 0,\n",
    "      'study_epoch': 0,\n",
    "      'study_arm': 0,\n",
    "      'study_cell': 0,\n",
    "      'entry': 0, 'exit': 0, 'timepoint': 0, 'timeline': 0, \n",
    "      'timing': 0, 'study_design': 0, 'study': 0, 'activity': 0, \n",
    "      'encounter': 0, 'bc_surrogate': 0 \n",
    "    }\n",
    "    self.dicts = {}\n",
    "\n",
    "  def increment_index(self, name):\n",
    "    self.id_index[name] += 1\n",
    "\n",
    "  def build_id(self, name):\n",
    "    self.increment_index(name)\n",
    "    return \"%s_%s\" % (name, self.id_index[name])\n",
    "\n",
    "  def add_code(self, code, code_system, code_system_version, decode):\n",
    "    id = self.build_id('code')\n",
    "    result = { '_type': 'Code', 'codeId': id, 'code': code, 'codeSystem': code_system, 'codeSystemVersion': code_system_version, 'decode': decode }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_organisation(self, scheme, identifier, name, type):\n",
    "    id = self.build_id('organisation')\n",
    "    result = { '_type': 'Organisation', 'organisationId': id, 'organisationIdentifierScheme': scheme, 'organisationIdentifier': identifier, 'organisationName': name, 'organisationType': type }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_study_identifier(self, identifier, scope):\n",
    "    id = self.build_id('study_identifier')\n",
    "    result = { '_type': 'StudyIdentifier', 'studyIdentifierId': id, 'studyIdentifier': identifier, 'studyIdentifierScope': scope }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_study_epoch(self, name, description):\n",
    "    id = self.build_id('study_epoch')\n",
    "    result = { '_type': 'StudyEpoch', 'studyEpochId': id, 'studyEpochName': name, 'studyEpochDescription': description, 'studyEpochType': \"\", 'previousStudyEpochId': \"\", 'nextStudyEpochId': \"\", 'encounters': [] }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_study_arm(self, name, description):\n",
    "    id = self.build_id('study_arm')\n",
    "    result = { '_type': 'StudyArm', 'studyArmId': id, 'studyArmName': name, 'studyArmDescription': description, 'studyArmType': None, 'studyArmDataOriginDescription': \"\", 'studyArmDataOriginType': None }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_study_cell(self, arm, epoch):\n",
    "    id = self.build_id('study_cell')\n",
    "    result = { '_type': 'StudyCell', 'studyCellId': id, 'studyArm': arm, 'studyEpoch': epoch, 'studyElements': [] }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_entry(self, description, timepoint_id):\n",
    "    id = self.build_id('entry')\n",
    "    result = { '_type': 'Entry', 'entryId': id, 'entryDescription': description, 'nextTimepointId': timepoint_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_exit(self):\n",
    "    id = self.build_id('exit')\n",
    "    result = { '_type': 'Exit', 'exitId': id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_timepoint(self, previous_timepoint_id, timing, activities, encounter):\n",
    "    id = self.build_id('timepoint')\n",
    "    result = { '_type': 'Timepoint', 'timepointId': id, 'nextTimepointId': None, 'scheduledAt': timing, 'timepointActivityIds': activities, 'timepointEncounterId': encounter }\n",
    "    self.dicts[id] = result\n",
    "    if not previous_timepoint_id == None:\n",
    "      self.dicts[previous_timepoint_id]['nextTimepointId'] = id\n",
    "    return result\n",
    "\n",
    "  def add_previous_timing(self, value, relative_to_from, window, to_id):\n",
    "    id = self.build_id('timing')\n",
    "    result = { '_type': 'Timing', 'timingId': id, 'type': \"after\", 'value': value, 'relativeToFrom': relative_to_from, 'window': window, 'relativeTo': to_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_next_timing(self, value, relative_to_from, window, to_id):\n",
    "    id = self.build_id('timing')\n",
    "    result = { '_type': 'Timing', 'timingId': id, 'type': \"next\", 'value': value, 'relativeToFrom': relative_to_from, 'window': window, 'relativeTo': to_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_anchor_timing(self, value, cycle=\"\"):\n",
    "    id = self.build_id('timing')\n",
    "    result = { '_type': 'Timing', 'timingId': id, 'type': \"anchor\", 'value': value, 'cycle': cycle, 'relativeToFrom': None, 'window': None, 'relativeTo': None }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_condition_timing(self, value, to_id):\n",
    "    id = self.build_id('timing')\n",
    "    result = { '_type': 'Condition', 'conditionId': id, 'type': \"condition\", 'value': value, 'relativeToFrom': None, 'window': None, 'relativeTo': to_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_cycle_start_timing(self, value):\n",
    "    id = self.build_id('timing')\n",
    "    result = { '_type': 'CycleStart', 'cycleStartId': id, 'type': \"cycle start\", 'value': value, 'relativeToFrom': None, 'window': None, 'relativeTo': None }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_timeline(self, entry, timepoints, exit):\n",
    "    id = self.build_id('timeline')\n",
    "    result = { '_type': 'Timeline', 'timelineId': id, 'timelineEntry': entry, 'timelineTimepoints': timepoints, 'timelineExit': exit }\n",
    "    self.dicts['id'] = result\n",
    "    return result\n",
    "  \n",
    "  def add_activity(self, name, description, conditional=False, conditional_reason=\"\", surrogates=[]):\n",
    "    id = self.build_id('activity')\n",
    "    result = { '_type': 'Activity', 'activityId': id, 'activityName': name, 'activityDescription': description, 'activityIsConditional': conditional, 'activityConditionalReason': conditional_reason, 'bcSurrogateIds': surrogates }\n",
    "    self.dicts['id'] = result\n",
    "    return result\n",
    "\n",
    "  def add_encounter(self, name, description, enc_type, env_setting, contact_modes):\n",
    "    id = self.build_id('encounter')\n",
    "    result = { '_type': 'Encounter', 'encounterId': id, 'encounterName': name, 'encounterDescription': description, 'encounterType': enc_type, 'encounterEnvironmentalSetting': env_setting, 'encounterContactMode': contact_modes }\n",
    "    self.dicts['id'] = result\n",
    "    return result\n",
    "\n",
    "  def add_biomedical_concept_surrogate(self, name, description, reference):\n",
    "    id = self.build_id('bc_surrogate')\n",
    "    result = { '_type': 'BCSurrogate', 'bcSurrogateId': id, 'bcSurrogateName': name, 'bcSurrogateDescription': description, 'bcSurrogateReference': reference }\n",
    "    self.dicts['id'] = result\n",
    "    return result\n",
    "\n",
    "  def add_study_design(self, intent_types, trial_types, intervention_model, cells):\n",
    "    #model, therapeutic_areas, cells, indications, objectives, populations, interventions, workflows, estimands, encounters, activities, surrogates\n",
    "    id = self.build_id('study_design')\n",
    "    result = { '_type': 'StudyDesign', 'studyDesignId': id, \n",
    "      'studyDesignName': \"\",\n",
    "      'studyDesignDescription': \"\",\n",
    "      'trialIntentTypes': intent_types,\n",
    "      'trialType': trial_types,\n",
    "      'interventionModel': intervention_model,\n",
    "      'studyCells': cells,\n",
    "      'studyIndications': [],\n",
    "      'studyInvestigationalInterventions': [],\n",
    "      'studyStudyDesignPopulations': [],\n",
    "      'studyObjectives': [],\n",
    "      'studyWorkflows': [],\n",
    "      'therapeuticAreas': [],\n",
    "      'studyEstimands': [],\n",
    "      'encounters': [],\n",
    "      'activities': [],\n",
    "      'studyDesignRationale': \"\",\n",
    "      'studyDesignBlindingScheme': None,\n",
    "      'biomedicalConcepts': [],\n",
    "      'bcCategories': [],\n",
    "      'bcSurrogates': []\n",
    "    }\n",
    "    self.dicts['id'] = result\n",
    "    return result\n",
    "    \n",
    "  def add_study(self, title, version, type, phase, ta, rationale, acronym, identifiers, protocols, designs):\n",
    "    id = self.build_id('study')\n",
    "    result = { '_type': 'Study', 'studyId': id, 'studyTitle': title, 'studyVersion': version, 'studyType': type, 'studyPhase': phase, 'businessTherapueticAreas': ta, 'studyRationale': rationale, 'studyAcronym': acronym, 'studyIdentifiers': identifiers, 'studyProtocolVersions': protocols, 'studyDesigns': designs }\n",
    "    self.dicts['id'] = result\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSheet():\n",
    "\n",
    "  def __init__(self, sheet):\n",
    "    self.sheet = sheet\n",
    "\n",
    "  def clean_cell(self, row, index, field_name):\n",
    "    try:\n",
    "      if pd.isnull(row[field_name]):\n",
    "        return \"\"\n",
    "      else:\n",
    "        return str(row[field_name]).strip()\n",
    "    except Exception as e:\n",
    "      print(\"Clean cell error (%s) for field '%s' in row %s\" % (e, field_name, index + 1))\n",
    "      return \"\"\n",
    "\n",
    "  def clean_cell_unnamed(self, rindex, cindex):\n",
    "    try:\n",
    "      if pd.isnull(self.sheet.iloc[rindex, cindex]):\n",
    "        return \"\"\n",
    "      else:\n",
    "        return self.sheet.iloc[rindex, cindex].strip()\n",
    "    except Exception as e:\n",
    "      print(\"Clean cell unnamed error (%s) for cell [%s, %s]\" % (e, rindex + 1, cindex + 1))\n",
    "      return \"\"\n",
    "\n",
    "  def cdisc_code_cell(self, row, index, field_name):\n",
    "    parts = self.clean_cell(row, index, field_name).split(\"=\")\n",
    "    return self.cdisc_code(code=parts[0], decode=parts[1])\n",
    "\n",
    "  def cdisc_code(self, code, decode):\n",
    "    json = DDFJson()\n",
    "    return json.add_code(code=code, code_system=\"http://www.cdisc.org\", code_system_version=\"2022-03-25\", decode=decode)\n",
    "\n",
    "  def double_link(self, items, id, prev, next):\n",
    "    #print(\"DL1\", items, id, prev, next)\n",
    "    for idx, item in enumerate(items):\n",
    "      if idx == 0:\n",
    "        print(\"DL2\", item, prev, item.keys())\n",
    "        if prev in item:\n",
    "          print(\"DL3\", item[prev])\n",
    "        item[prev] = None\n",
    "      else:\n",
    "        uuid = items[idx-1][id]\n",
    "        item[prev] = uuid\n",
    "      if idx == len(items)-1:  \n",
    "        item[next] = None\n",
    "      else:\n",
    "        uuid = items[idx+1][id]\n",
    "        item[next] = uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudyIdentifiersSheet(BaseSheet):\n",
    "\n",
    "  def __init__(self, file_path):\n",
    "    try:\n",
    "      super().__init__(pd.read_excel(open(file_path, 'rb'), sheet_name='studyIdentifiers'))\n",
    "      self.identifiers = []\n",
    "      self.process_sheet()\n",
    "    except Exception as e:\n",
    "      print(\"Oops!\", e, \"occurred.\")\n",
    "      traceback.print_exc()\n",
    "      \n",
    "  def process_sheet(self):\n",
    "    json = DDFJson()\n",
    "    self.identifiers = []\n",
    "    for index, row in self.sheet.iterrows():\n",
    "      organisation_type_key = self.clean_cell(row, index, 'organisationType')\n",
    "      if organisation_type_key.lower() == \"sponsor\":\n",
    "        organisation_type = self.study_sponsor()\n",
    "      elif organisation_type_key.lower() == \"registry\":\n",
    "        organisation_type = self.study_registry()\n",
    "      elif organisation_type_key.lower() == \"regulatory\":\n",
    "        organisation_type = self.regulatory()\n",
    "      else:\n",
    "        organisation_type = self.study_sponsor()\n",
    "      organisation = json.add_organisation(\n",
    "        scheme=self.clean_cell(row, index, 'organisationIdentifierScheme'), \n",
    "        identifier=self.clean_cell(row, index, 'organisationIdentifier'),\n",
    "        name=self.clean_cell(row, index, 'organisationName'),\n",
    "        type=organisation_type\n",
    "      )\n",
    "      self.identifiers.append(json.add_study_identifier(identifier=self.clean_cell(row, index, 'studyIdentifier'), scope=organisation))\n",
    "    \n",
    "  def study_registry(self):\n",
    "    return self.cdisc_code(code=\"C93453\", decode=\"Study Registry\")\n",
    "\n",
    "  def study_sponsor(self):\n",
    "    return self.cdisc_code(code=\"C70793\", decode=\"Clinical Study Sponsor\")\n",
    "\n",
    "  def regulatory(self):\n",
    "    return self.cdisc_code(code=\"C188863\", decode=\"Regulatory Agency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudyDesignSheet(BaseSheet):\n",
    "\n",
    "  def __init__(self, file_path):\n",
    "    try:\n",
    "      super().__init__(pd.read_excel(open(file_path, 'rb'), sheet_name='studyDesign', header=None))\n",
    "      self.epochs = []\n",
    "      self.epoch_map = {}\n",
    "      self.arms = []\n",
    "      self.cells = []\n",
    "      self.study_designs = []\n",
    "      self.process_sheet()\n",
    "    except Exception as e:\n",
    "      print(\"Oops!\", e, \"occurred.\")\n",
    "      traceback.print_exc()\n",
    "\n",
    "  def process_sheet(self):\n",
    "    json = DDFJson()\n",
    "    #print(\"COLS\", len(self.sheet.columns))\n",
    "    for rindex, row in self.sheet.iterrows():\n",
    "      for cindex in range(0, len(self.sheet.columns)):\n",
    "        cell = self.clean_cell_unnamed(rindex, cindex)\n",
    "        #print(\"CELL [%s,%s] %s\" % (rindex, cindex, cell))\n",
    "        if rindex == 0:\n",
    "          if cindex != 0:\n",
    "            epoch = json.add_study_epoch(name=cell, description=cell)\n",
    "            self.epoch_map[cell] = epoch\n",
    "            self.epochs.append(epoch)\n",
    "        else:\n",
    "          if cindex == 0:\n",
    "            self.arms.append(json.add_study_arm(name=cell, description=cell))\n",
    "          else:\n",
    "            self.cells.append(json.add_study_cell(arm=self.arms[-1], epoch=self.epochs[cindex-1]))\n",
    "\n",
    "    self.double_link(self.epochs, 'studyEpochId', 'previousStudyEpochId', 'nextStudyEpochId')\n",
    "    trial_type = self.cdisc_code('C12345', 'Observational')\n",
    "    int_model = self.cdisc_code('C12346', 'None')\n",
    "    study_design = json.add_study_design(cells=self.cells, intent_types=[], trial_types=[trial_type], intervention_model=int_model)\n",
    "    #print(\"STUDY_DESIGN:\", study_design)\n",
    "    self.study_designs.append(study_design)\n",
    "\n",
    "  def link_encounters(self, encounter_map):\n",
    "    for epoch_name, encounters in encounter_map.items():\n",
    "      #print(\"LINK: %s %s\" % (epoch_name, encounter))\n",
    "      epoch = self.epoch_map[epoch_name]\n",
    "      for encounter in encounters:\n",
    "        epoch.encounters.append(encounter)\n",
    "  \n",
    "  def link_wfi(self, wfi):\n",
    "    #print(\"WFI:\", wfi)\n",
    "    self.study_designs[0].studyWorkflows = [Workflow(workflowDesc=\"SoA\", workflowItems=wfi)]\n",
    "    #print(\"SDWF:\", self.study_designs[0].studyWorkflows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudySoASheet(BaseSheet):\n",
    "\n",
    "  EPOCH_ROW = 0\n",
    "  CYCLE_ROW = 1\n",
    "  CYCLE_START_ROW = 2\n",
    "  CYCLE_PERIOD_ROW = 3\n",
    "  CYCLE_END_RULE_ROW = 4\n",
    "  TIMING_ROW = 5\n",
    "  VISIT_LABEL_ROW = 6\n",
    "  VISIT_WINDOW_ROW = 7\n",
    "\n",
    "  HEADER_ROW = 8\n",
    "  FIRST_ACTIVITY_ROW = 9\n",
    "\n",
    "  ACTIVITY_COL = 0\n",
    "  CHILD_ACTIVITY_COL = 1\n",
    "  BC_COL = 2\n",
    "  FIRST_VISIT_COL = 3\n",
    "\n",
    "  def __init__(self, file_path):\n",
    "    try:\n",
    "      super().__init__(pd.read_excel(open(file_path, 'rb'), sheet_name='soa', header=None))\n",
    "      self.timeline = {}\n",
    "      #self.epoch_encounter_map = {}\n",
    "      #self.activity_map = {}\n",
    "      self.row_activities_map = []\n",
    "      self.activity_bc_map = {}\n",
    "      self.sheet = self.sheet.fillna(method='ffill', axis=1)\n",
    "      self.cycles = self.extract_cycles()\n",
    "      self.timepoints = self.extract_timepoints()\n",
    "      self.encounters = self.extract_encounters()\n",
    "      self.activity_bc_map, self.row_activities_map, self.activities = self.extract_activities_and_bcs()\n",
    "      self.tp_activities = self.extract_timepoint_activities_map()\n",
    "\n",
    "      self.process_sheet()\n",
    "    except Exception as e:\n",
    "      print(\"Oops!\", e, \"occurred.\")\n",
    "      traceback.print_exc()\n",
    "\n",
    "  def get_cycle_cell(self, row_index, col_index):\n",
    "    is_null = pd.isnull(self.sheet.iloc[row_index, col_index])\n",
    "    if is_null:\n",
    "      return \"\", True\n",
    "    else:\n",
    "      value = str(self.sheet.iloc[row_index, col_index])\n",
    "      if value.upper() == \"-\":\n",
    "        return \"\", True\n",
    "      else:\n",
    "        return value, False\n",
    "\n",
    "  def previous_index(index):\n",
    "    if index == 0:\n",
    "      return 0\n",
    "    else:\n",
    "      return index - 1\n",
    "\n",
    "  def build_cycle_record(self, index, col_index, cycle):\n",
    "    cycle_start_index = index\n",
    "    cycle_start, is_null = self.get_cycle_cell(self.CYCLE_START_ROW, col_index)\n",
    "    cycle_period, is_null = self.get_cycle_cell(self.CYCLE_PERIOD_ROW, col_index)\n",
    "    cycle_end_rule, is_null = self.get_cycle_cell(self.CYCLE_END_RULE_ROW, col_index)\n",
    "    return { \n",
    "      'start_index': cycle_start_index, \n",
    "      'cycle': cycle, \n",
    "      'start': cycle_start, \n",
    "      'period': cycle_period, \n",
    "      'end_rule': cycle_end_rule \n",
    "    }\n",
    "\n",
    "  def extract_cycles(self):\n",
    "    cycles = []\n",
    "    timepoint_index = -1\n",
    "    cycle_start_index = None\n",
    "    in_cycle = False\n",
    "    prev_cycle = None\n",
    "    for col_index in range(self.sheet.shape[1]):\n",
    "      if col_index >= self.FIRST_VISIT_COL:\n",
    "        timepoint_index += 1\n",
    "        cycle, cycle_is_null = self.get_cycle_cell(self.CYCLE_ROW, col_index)\n",
    "        if cycle_is_null:\n",
    "          if in_cycle:\n",
    "            cycle_record['end_index'] = self.previous_index(timepoint_index)\n",
    "            cycles.append(cycle_record)\n",
    "            in_cycle = False\n",
    "          else:\n",
    "            pass # Do nothing\n",
    "        else:\n",
    "          cycle = str(cycle)\n",
    "          if not in_cycle:\n",
    "            in_cycle = True\n",
    "            cycle_record = self.build_cycle_record(timepoint_index, col_index, cycle)\n",
    "          elif prev_cycle == cycle:\n",
    "            pass # Do nothing\n",
    "          else:\n",
    "            cycle_record['end_index'] = self.previous_index(timepoint_index)\n",
    "            cycles.append(cycle_record)\n",
    "            cycle_record = self.build_cycle_record(timepoint_index, col_index, cycle)\n",
    "        prev_cycle = cycle\n",
    "    return cycles\n",
    "\n",
    "  def get_timing_cell(self, row_index, col_index):\n",
    "    is_null = pd.isnull(self.sheet.iloc[row_index, col_index])\n",
    "    if is_null:\n",
    "      return \"\", True\n",
    "    else:\n",
    "      return self.sheet.iloc[row_index, col_index], False\n",
    "\n",
    "  def get_activity_cell(self, row_index, col_index):\n",
    "    is_null = pd.isnull(self.sheet.iloc[row_index, col_index])\n",
    "    if is_null:\n",
    "      return \"\", True\n",
    "    else:\n",
    "      value = self.sheet.iloc[row_index, col_index]\n",
    "      if value == '-':\n",
    "        return \"\", True\n",
    "      else:\n",
    "        return self.sheet.iloc[row_index, col_index], False\n",
    "  \n",
    "  def get_observation_cell(self, row_index, col_index):\n",
    "    is_null = pd.isnull(self.sheet.iloc[row_index, col_index])\n",
    "    if is_null:\n",
    "      return \"\", \"\", True\n",
    "    else:\n",
    "      value = self.sheet.iloc[row_index, col_index]\n",
    "      if value == '-':\n",
    "        return \"\", \"\", True\n",
    "      else:\n",
    "        parts = value.split(':')\n",
    "        if parts[0].lower() == \"bc\":\n",
    "          return \"bc\", parts[1], False\n",
    "        else:\n",
    "          return \"\", \"\", True\n",
    "\n",
    "  def get_relative_ref(self, part):\n",
    "    if len(part) > 1:\n",
    "      return int(part[1:])\n",
    "    else:\n",
    "      return 1\n",
    "\n",
    "  def get_timing_type(self, col_index):\n",
    "    timing_type = \"\"\n",
    "    rel_ref = 0\n",
    "    timing_value = \"\"\n",
    "    timing_info, timing_info_is_null = self.get_timing_cell(self.TIMING_ROW, col_index)\n",
    "    if not timing_info_is_null:\n",
    "      timing_parts = timing_info.split(\":\")\n",
    "      if timing_parts[0].upper()[0] == \"A\":\n",
    "        timing_type = \"anchor\"\n",
    "        rel_ref = 0\n",
    "      if timing_parts[0].upper()[0] == \"P\":\n",
    "        timing_type = \"previous\"\n",
    "        rel_ref = self.get_relative_ref(timing_parts[0]) * -1\n",
    "      elif timing_parts[0].upper()[0] == \"N\":\n",
    "        timing_type = \"next\"\n",
    "        rel_ref = self.get_relative_ref(timing_parts[0])\n",
    "      elif timing_parts[0].upper()[0] == \"C\":\n",
    "        timing_type = \"cycle start\"\n",
    "        rel_ref = self.get_relative_ref(timing_parts[0])\n",
    "      if len(timing_parts) == 2:\n",
    "        timing_value = timing_parts[1].strip()\n",
    "    #print(\"TIMING: col_index (%s) - FIRST_VISIT_COL (%s) + rel_ref (%s)\" % (col_index, FIRST_VISIT_COL, rel_ref))\n",
    "    return { 'type': timing_type, 'ref': col_index - self.FIRST_VISIT_COL + rel_ref, 'value': timing_value, 'cycle': None }\n",
    "\n",
    "  def extract_timepoints(self):\n",
    "    timepoints = []\n",
    "    for col_index in range(self.sheet.shape[1]):\n",
    "      if col_index >= self.FIRST_VISIT_COL:\n",
    "        record = self.get_timing_type(col_index)\n",
    "        timepoints.append(record)\n",
    "    return timepoints\n",
    "\n",
    "  def get_encounter_cell(self, row_index, col_index):\n",
    "    is_null = pd.isnull(self.sheet.iloc[row_index, col_index])\n",
    "    if is_null:\n",
    "      return \"\", True\n",
    "    else:\n",
    "      return self.sheet.iloc[row_index, col_index], False\n",
    "\n",
    "  def get_encounter_details(self, col_index):\n",
    "    label = \"\"\n",
    "    window = \"\"\n",
    "    label, label_is_null = self.get_encounter_cell(self.VISIT_LABEL_ROW, col_index)\n",
    "    window, window_is_null = self.get_encounter_cell(self.VISIT_WINDOW_ROW, col_index)\n",
    "    return { 'label': label, 'window': window }\n",
    "\n",
    "  def extract_encounters(self):\n",
    "    encounters = []\n",
    "    for col_index in range(self.sheet.shape[1]):\n",
    "      if col_index >= self.FIRST_VISIT_COL:\n",
    "        record = self.get_encounter_details(col_index)\n",
    "        encounters.append(record)\n",
    "    return encounters\n",
    "\n",
    "  def extract_activities_and_bcs(self):\n",
    "    activity_bc_map = {}\n",
    "    row_activities_map = []\n",
    "    activities = []\n",
    "    prev_activity = None\n",
    "    for row_index, col_def in self.sheet.iterrows():\n",
    "      if row_index >= self.FIRST_ACTIVITY_ROW:\n",
    "        activity, activity_is_null = self.get_activity_cell(row_index, self.CHILD_ACTIVITY_COL)\n",
    "        if activity_is_null:\n",
    "          if not prev_activity == None:\n",
    "            row_activities_map.append(prev_activity)\n",
    "            activity = prev_activity\n",
    "        else:\n",
    "          activities.append(activity)\n",
    "          row_activities_map.append(activity)\n",
    "        prev_activity = activity\n",
    "        obs_type, obs_name, obs_is_null = self.get_observation_cell(row_index, self.BC_COL)\n",
    "        if not obs_is_null:\n",
    "          if obs_type == \"bc\":\n",
    "            if not activity in activity_bc_map:\n",
    "              activity_bc_map[activity] = { 'bc': [] }  \n",
    "            activity_bc_map[activity]['bc'].append(obs_name)\n",
    "    return activity_bc_map, row_activities_map, activities\n",
    "  \n",
    "  def extract_timepoint_activities_map(self):\n",
    "    timepoint_activity_map = []\n",
    "    activity_dict = {}\n",
    "    for activity in self.activities:\n",
    "      activity_dict[activity] = False\n",
    "    for tp in self.timepoints:\n",
    "      timepoint_activity_map.append(dict(activity_dict))\n",
    "    for index in range(self.sheet.shape[1]):\n",
    "      if index >= self.FIRST_VISIT_COL:\n",
    "        column = self.sheet.iloc[:, index]\n",
    "        row = 0\n",
    "        for col in column:\n",
    "          if row >= self.FIRST_ACTIVITY_ROW:\n",
    "            if not pd.isnull(col):\n",
    "              if col.upper() == \"X\":\n",
    "                print(\"RA\", self.row_activities_map, row)\n",
    "                activity = self.row_activities_map[row - self.FIRST_ACTIVITY_ROW]\n",
    "                tp_index = index - self.FIRST_VISIT_COL\n",
    "                timepoint_activity_map[tp_index][activity] = True\n",
    "          row += 1\n",
    "    return timepoint_activity_map\n",
    "\n",
    "  def process_sheet(self):\n",
    "  #def process_timepoints(self, timepoints, cycles, activities, tp_activities, encounters):\n",
    "    json = DDFJson()\n",
    "    tps = []\n",
    "    acts = []\n",
    "    encs = []\n",
    "    bcs = []\n",
    "    acts_map = {}\n",
    "    timing = []\n",
    "    cycle_offset = 0\n",
    "    for index, timepoint in enumerate(self.timepoints):\n",
    "      timepoint['activity_index'] = index\n",
    "      timepoint['encounter_index'] = index\n",
    "    for cycle in self.cycles:\n",
    "      start_index = cycle['start_index'] + cycle_offset\n",
    "      self.timepoints.insert(start_index, { 'type': 'anchor', 'ref': 0, 'value': cycle['start'], 'activity_index': None, 'encounter_index': None, 'cycle': cycle['cycle'] })\n",
    "      cycle_offset += 1\n",
    "      end_index = cycle['end_index'] + cycle_offset + 1\n",
    "      self.timepoints.insert(end_index, { 'type': 'previous', 'ref': end_index - 1, 'value': cycle['period'], 'activity_index': None, 'encounter_index': None, 'cycle': None })\n",
    "      cycle_offset += 1\n",
    "      end_index = cycle['end_index'] + cycle_offset + 1\n",
    "      self.timepoints.insert(end_index, { 'type': 'condition', 'ref': start_index , 'value': cycle['end_rule'], 'activity_index': None, 'encounter_index': None, 'cycle': None })\n",
    "      cycle_offset += 1\n",
    "    previous_tp_id = None\n",
    "    for activity in self.activities:\n",
    "      a_bcs = []\n",
    "      if activity in self.activity_bc_map:\n",
    "        for a in self.activity_bc_map[activity]['bc']:\n",
    "          bc = json.add_biomedical_concept_surrogate(a, a, \"\")\n",
    "          a_bcs.append(bc['bcSurrogateId'])\n",
    "          bcs.append(bc)\n",
    "      acts.append(json.add_activity(activity, activity, False, \"\", a_bcs))\n",
    "      acts_map[activity] = acts[-1]['activityId']\n",
    "    for encounter in self.encounters:\n",
    "      encs.append(json.add_encounter(encounter['label'], encounter['label'], None, None, []))\n",
    "    for timepoint in self.timepoints:\n",
    "      activity_ids = []\n",
    "      encounter_id = None\n",
    "      if not timepoint['activity_index'] == None:\n",
    "        source = self.tp_activities[timepoint['activity_index']]\n",
    "        for k, v in source.items():\n",
    "          if v:\n",
    "            activity_ids.append(acts_map[k])\n",
    "      if not timepoint['encounter_index'] == None:\n",
    "        encounter_id = encs[timepoint['encounter_index']]['encounterId']\n",
    "      tps.append(json.add_timepoint(previous_tp_id, None, activity_ids, encounter_id))\n",
    "      previous_tp_id = tps[-1]['timepointId']\n",
    "    for index, timepoint in enumerate(self.timepoints):\n",
    "      if timepoint['type'] == 'condition':\n",
    "        tps[index]['cycleId'] = tps[timepoint['ref']]['timepointId']\n",
    "        tps[index]['_type'] = 'Condition'\n",
    "    for timepoint in self.timepoints:\n",
    "      if timepoint['type'] == 'next':\n",
    "        timing.append(json.add_next_timing(timepoint['value'], 'StartToStart', None, tps[timepoint['ref']]['timepointId']))\n",
    "      elif timepoint['type'] == 'previous':\n",
    "        timing.append(json.add_previous_timing(timepoint['value'], 'StartToStart', None, tps[timepoint['ref']]['timepointId']))\n",
    "      elif timepoint['type'] == 'anchor':\n",
    "        timing.append(json.add_anchor_timing(timepoint['value'], timepoint['cycle']))\n",
    "      elif timepoint['type'] == 'condition':\n",
    "        #timing.append(json.add_condition_timing(timepoint['value']))\n",
    "        timing.append({})\n",
    "      elif timepoint['type'] == 'cycle start':\n",
    "        timing.append(json.add_cycle_start_timing(timepoint['value']))\n",
    "      elif timepoint['type'] == '':\n",
    "        timing.append({})\n",
    "    for index, tp in enumerate(tps):\n",
    "      tp['scheduledAt'] = timing[index]\n",
    "    entry = json.add_entry('Main timeline', tps[0]['timepointId'])\n",
    "    exit = json.add_exit()\n",
    "    tps[-1]['exit'] = exit\n",
    "    self.timeline = json.add_timeline(entry, tps, exit)\n",
    "    \n",
    "    # def export(self, node):\n",
    "    #   return self.export_node(node)\n",
    "\n",
    "    # def export_node(self, node):\n",
    "    #   if type(node) == list:\n",
    "    #     result = []\n",
    "    #     for item in node:\n",
    "    #       result.append(self.export_node(item))\n",
    "    #     return result\n",
    "    #   elif type(node) == dict:\n",
    "    #     result = {}\n",
    "    #     for key, value in node.items():\n",
    "    #       if key.startswith('_'):\n",
    "    #         continue\n",
    "    #       result[key] = self.export_node(value)\n",
    "    #     return result\n",
    "    #   else:\n",
    "    #     return node\n",
    "\n",
    "  # def process_sheet(self):\n",
    "  #   #print(\"SIZE %s x %s\" % (self.sheet.shape[0], len(self.sheet.columns)))\n",
    "  #   wfi_index = 1\n",
    "  #   for rindex, row in self.sheet.iterrows():\n",
    "  #     for cindex in range(0, len(self.sheet.columns)):\n",
    "  #       #print(\"A %s %s\" % (rindex, cindex))  \n",
    "  #       cell = self.clean_cell_unnamed(rindex, cindex)\n",
    "  #       #print(\"CELL [%s,%s] %s\" % (rindex, cindex, cell))\n",
    "  #       if rindex == 0:\n",
    "  #         pass\n",
    "  #       elif rindex == 1:\n",
    "  #         if cindex != 0:\n",
    "  #           epoch = self.clean_cell_unnamed(rindex - 1, cindex)\n",
    "  #           description = self.clean_cell_unnamed(rindex + 1, cindex)\n",
    "  #           encounter = Encounter(uuid=str(uuid4()), encounterName=cell, encounterDesc=description)\n",
    "  #           if not epoch in self.epoch_encounter_map:\n",
    "  #             self.epoch_encounter_map[epoch] = []\n",
    "  #           self.epoch_encounter_map[epoch].append(encounter)\n",
    "  #           self.encounters.append(encounter)\n",
    "  #       elif rindex == 2:\n",
    "  #         pass\n",
    "  #       else:\n",
    "  #         if cindex == 0:\n",
    "  #           activity = Activity(uuid=str(uuid4()), activityName=cell, activityDesc=cell)\n",
    "  #           self.activity_map[cell] = activity\n",
    "  #           self.activities.append(activity)\n",
    "  #         else:\n",
    "  #           if cell.lower() == \"x\":\n",
    "  #             self.workflow_items.append(WorkflowItem(uuid=str(uuid4()), workflowItemDesc=\"WFI%s\" % (wfi_index), workflowItemActivity=self.activities[-1], workflowItemEncounter=self.encounters[cindex-1]))\n",
    "  #             wfi_index += 1\n",
    "  #   self.double_link(self.activities, 'uuid', 'previousActivityId', 'nextActivityId')\n",
    "  #   self.double_link(self.encounters, 'uuid', 'previousEncounterId', 'nextEncounterId')\n",
    "  #   self.double_link(self.workflow_items, 'uuid', 'previousWorkflowItemId', 'nextWorkflowItemId')\n",
    "\n",
    "  # def link_study_data(self, study_data_map):\n",
    "  #   for activity_name, study_data in study_data_map.items():\n",
    "  #     activity = self.activity_map[activity_name]\n",
    "  #     activity.studyDataCollection = study_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudySheet(BaseSheet):\n",
    "\n",
    "  def __init__(self, file_path):\n",
    "    try:\n",
    "      super().__init__(pd.read_excel(open(file_path, 'rb'), sheet_name='study'))\n",
    "      self.study = None\n",
    "      self.study_identifiers = StudyIdentifiersSheet(file_path)\n",
    "      self.study_design = StudyDesignSheet(file_path)\n",
    "      self.soa = StudySoASheet(file_path)\n",
    "      #self.activities = StudyActivitiesSheet(file_path)\n",
    "      #self.soa.link_study_data(self.activities.activity_map)\n",
    "      #self.study_designs.link_encounters(self.soa.epoch_encounter_map)\n",
    "      #self.study_designs.link_wfi(self.soa.workflow_items)\n",
    "      print(\"Study 1\", self.soa.timeline)\n",
    "      self.process_sheet()\n",
    "      print(\"Study 2\")\n",
    "    except Exception as e:\n",
    "      print(\"Oops!\", e, \"occurred.\")\n",
    "      traceback.print_exc()\n",
    "\n",
    "  def process_sheet(self):\n",
    "    json = DDFJson()\n",
    "    for index, row in self.sheet.iterrows():\n",
    "      study_phase = self.cdisc_code_cell(row, index, \"studyPhase\")\n",
    "      study_version = self.clean_cell(row, index, \"studyVersion\")\n",
    "      study_type = self.cdisc_code_cell(row, index, \"studyType\")\n",
    "      study_title = self.clean_cell(row, index, \"studyTitle\")\n",
    "      self.study = json.add_study(\n",
    "        title=study_title,\n",
    "        version=study_version,\n",
    "        type=study_type,\n",
    "        phase=study_phase,\n",
    "        ta=None,\n",
    "        rationale=\"\",\n",
    "        acronym=\"\",\n",
    "        identifiers=self.study_identifiers.identifiers,\n",
    "        protocols=[],\n",
    "        designs=[]\n",
    "      )\n",
    "\n",
    "  def study_sponsor(self):\n",
    "    return self.cdisc_code(code=\"C93453\", decode=\"Study Registry\")\n",
    "\n",
    "  def study_regulatory(self):\n",
    "    return self.cdisc_code(code=\"C93453\", decode=\"Study Registry\")\n",
    "\n",
    "  def the_study(self):\n",
    "    return self.study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImportExcel():\n",
    "\n",
    "  def __init__(self, file_path):\n",
    "    self.study = StudySheet(file_path)\n",
    "\n",
    "  def identifier(self):\n",
    "    study = self.study.the_study()\n",
    "    if study == None:\n",
    "      return None\n",
    "    else:\n",
    "      return study.study_identifier()\n",
    "\n",
    "  def save(self):\n",
    "    return self.study.study.save()\n",
    "\n",
    "  def the_study(self):\n",
    "    return self.study.the_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDFVisual():\n",
    "\n",
    "  def __init__(self):\n",
    "    self.nodes = []\n",
    "    self.edges = []\n",
    "    self.add_edges = []\n",
    "    self.node_index = 1\n",
    "    self.edge_index = 1\n",
    "    self.id_node_index_map = {}\n",
    "    self.type_id_field_map = { \n",
    "      'Entry': 'entryId',\n",
    "      'Exit': 'exitId',\n",
    "      'Timeline': 'timelineId',\n",
    "      'Timepoint': 'timepointId',\n",
    "      'Timing': 'timingId',\n",
    "      'Condition': 'timepointId',\n",
    "      'CycleStart': 'cycleStartId',\n",
    "      'StudyDesign': 'studyDesignId',\n",
    "      'Activity': 'activityId',\n",
    "      'Encounter': 'encounterId',\n",
    "      'BCSurrogate': 'bcSurrogateId',\n",
    "      'Study': 'studyId'\n",
    "    }\n",
    "    self.edge_attributes = [\n",
    "      'relativeTo',\n",
    "      'nextTimepointId',\n",
    "      'cycleId',\n",
    "      'timepointActivityIds',\n",
    "      'timepointEncounterId',\n",
    "      'bcSurrogateIds',\n",
    "      'bcCategoryIds',\n",
    "      'biomedicalConceptIds',\n",
    "    ]\n",
    "    \n",
    "  def get_id_field_and_klass(self, node):\n",
    "    klass = node['_type']\n",
    "    return self.type_id_field_map[klass], klass\n",
    "\n",
    "  def draw(self, json):\n",
    "    self.process_node(json)\n",
    "    for edge in self.add_edges:\n",
    "      if edge['end'] in self.id_node_index_map:\n",
    "        edge['id'] = self.edge_index\n",
    "        edge['end'] = self.id_node_index_map[edge['end']]\n",
    "        self.edges.append(edge)\n",
    "        self.edge_index += 1\n",
    "      else:\n",
    "        print(\"***** %s -edge-> %s *****\" % (edge['start'], edge['end']))\n",
    "    return self.nodes, self.edges\n",
    "  \n",
    "  def process_node(self, node):\n",
    "    if type(node) == list:\n",
    "      result = []\n",
    "      for item in node:\n",
    "        indexes = self.process_node(item)\n",
    "        result = result + indexes\n",
    "      return result\n",
    "    elif type(node) == dict:\n",
    "      if node == {}:\n",
    "        return []\n",
    "      properties = {}\n",
    "      id_field, klass = self.get_id_field_and_klass(node)\n",
    "      if node[id_field] in self.id_node_index_map:\n",
    "        return [self.id_node_index_map[node[id_field]]]\n",
    "      this_node_index = self.node_index\n",
    "      self.node_index += 1\n",
    "      for key, value in node.items():\n",
    "        if key in self.edge_attributes:\n",
    "          if type(value) == list:\n",
    "            for item in value:\n",
    "              self.add_edges.append( { 'start': this_node_index, 'end': item, 'properties': {'label': key}})\n",
    "          else:\n",
    "            self.add_edges.append( { 'start': this_node_index, 'end': value, 'properties': {'label': key}})\n",
    "        else:\n",
    "          indexes = self.process_node(value)\n",
    "          if indexes == []:\n",
    "            properties[key] = value\n",
    "          else:\n",
    "            for index in indexes:\n",
    "              self.edges.append( {'id': self.edge_index, 'start': this_node_index, 'end': index, 'properties': {'label': key}})\n",
    "              self.edge_index += 1\n",
    "      properties['node_type'] = klass\n",
    "      properties['label'] = node[id_field]\n",
    "      self.nodes.append({ 'id': this_node_index, 'properties': properties })\n",
    "      self.id_node_index_map[properties[id_field]] = this_node_index\n",
    "      return [this_node_index]\n",
    "    else:\n",
    "      return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_file(data, filename):\n",
    "  with open('source_data/%s.json' % (filename), 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(data, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL2 {'_type': 'StudyEpoch', 'studyEpochId': 'study_epoch_1', 'studyEpochName': 'Screening', 'studyEpochDescription': 'Screening', 'studyEpochType': '', 'previousStudyEpochId': '', 'nextStudyEpochId': '', 'encounters': []} previousStudyEpochId dict_keys(['_type', 'studyEpochId', 'studyEpochName', 'studyEpochDescription', 'studyEpochType', 'previousStudyEpochId', 'nextStudyEpochId', 'encounters'])\n",
      "DL3 \n",
      "RA ['Demographics', 'Demographics', 'Demographics', 'Something Else'] 9\n",
      "RA ['Demographics', 'Demographics', 'Demographics', 'Something Else'] 12\n",
      "RA ['Demographics', 'Demographics', 'Demographics', 'Something Else'] 12\n",
      "RA ['Demographics', 'Demographics', 'Demographics', 'Something Else'] 12\n",
      "RA ['Demographics', 'Demographics', 'Demographics', 'Something Else'] 12\n",
      "RA ['Demographics', 'Demographics', 'Demographics', 'Something Else'] 12\n",
      "Study 1 {'_type': 'Timeline', 'timelineId': 'timeline_1', 'timelineEntry': {'_type': 'Entry', 'entryId': 'entry_1', 'entryDescription': 'Main timeline', 'nextTimepointId': 'timepoint_1'}, 'timelineTimepoints': [{'_type': 'Timepoint', 'timepointId': 'timepoint_1', 'nextTimepointId': 'timepoint_2', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_1', 'type': 'next', 'value': '0..2 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}, 'timepointActivityIds': ['activity_1', 'activity_2'], 'timepointEncounterId': 'encounter_1'}, {'_type': 'Timepoint', 'timepointId': 'timepoint_2', 'nextTimepointId': 'timepoint_3', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_2', 'type': 'next', 'value': 'Pre Dose', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_3'}, 'timepointActivityIds': ['activity_2'], 'timepointEncounterId': 'encounter_2'}, {'_type': 'Timepoint', 'timepointId': 'timepoint_3', 'nextTimepointId': 'timepoint_4', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_3', 'type': 'anchor', 'value': '', 'cycle': None, 'relativeToFrom': None, 'window': None, 'relativeTo': None}, 'timepointActivityIds': ['activity_2'], 'timepointEncounterId': 'encounter_3'}, {'_type': 'Timepoint', 'timepointId': 'timepoint_4', 'nextTimepointId': 'timepoint_5', 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_4', 'type': 'after', 'value': '+24 Hours', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_3'}, 'timepointActivityIds': ['activity_2'], 'timepointEncounterId': 'encounter_4'}, {'_type': 'Timepoint', 'timepointId': 'timepoint_5', 'nextTimepointId': None, 'scheduledAt': {'_type': 'Timing', 'timingId': 'timing_5', 'type': 'after', 'value': '+7 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_4'}, 'timepointActivityIds': ['activity_2'], 'timepointEncounterId': 'encounter_5', 'exit': {'_type': 'Exit', 'exitId': 'exit_1'}}], 'timelineExit': {'_type': 'Exit', 'exitId': 'exit_1'}}\n",
      "Study 2\n",
      "{'_type': 'Study', 'studyId': 'study_1', 'studyTitle': 'Simple Test 1', 'studyVersion': '1', 'studyType': {'_type': 'Code', 'codeId': 'code_1', 'code': 'C98388', 'codeSystem': 'http://www.cdisc.org', 'codeSystemVersion': '2022-03-25', 'decode': 'Interventional Study'}, 'studyPhase': {'_type': 'Code', 'codeId': 'code_1', 'code': 'C15602', 'codeSystem': 'http://www.cdisc.org', 'codeSystemVersion': '2022-03-25', 'decode': 'Phase III Trial'}, 'businessTherapueticAreas': None, 'studyRationale': '', 'studyAcronym': '', 'studyIdentifiers': [{'_type': 'StudyIdentifier', 'studyIdentifierId': 'study_identifier_1', 'studyIdentifier': 'NCT12345678', 'studyIdentifierScope': {'_type': 'Organisation', 'organisationId': 'organisation_1', 'organisationIdentifierScheme': 'USGOV', 'organisationIdentifier': 'CT-GOV', 'organisationName': 'ClinicalTrials.gov', 'organisationType': {'_type': 'Code', 'codeId': 'code_1', 'code': 'C93453', 'codeSystem': 'http://www.cdisc.org', 'codeSystemVersion': '2022-03-25', 'decode': 'Study Registry'}}}], 'studyProtocolVersions': [], 'studyDesigns': []}\n"
     ]
    }
   ],
   "source": [
    "#study = \"Roche Phase 3 NCT04320615\"\n",
    "#study = \"cycles_1_v2\"\n",
    "study = \"simple_1\"\n",
    "#study = \"simple_2\"\n",
    "\n",
    "notebook_path = os.path.abspath(\"notebook.ipynb\")\n",
    "file_path = os.path.join(os.path.dirname(notebook_path), \"source_data/%s.xlsx\" % (study))\n",
    "x = ImportExcel(file_path)\n",
    "print(x.the_study())\n",
    "\n",
    "\n",
    "#print(\"CYCLES\", cycles)\n",
    "#print(\"TIMEPOINTS\", timepoints)\n",
    "#print(\"ENCOUNTERS\", encounters)\n",
    "#print(\"ACTIVITIES\", activities)\n",
    "#print(\"TP ACTIVITIES\", tp_activities)\n",
    "\n",
    "#x = DDFJson()\n",
    "#node = x.process_timepoints(timepoints, cycles, activities, tp_activities, encounters)\n",
    "#save_as_file(x.export(node), study)\n",
    "\n",
    "#y = DDFVisual()\n",
    "#nodes, edges = y.draw(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[247], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m graph_widget\u001b[39m.\u001b[39morthogonal_layout()\n\u001b[1;32m     55\u001b[0m graph_widget\u001b[39m.\u001b[39mset_directed(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 57\u001b[0m graph_widget\u001b[39m.\u001b[39mset_nodes(nodes)\n\u001b[1;32m     58\u001b[0m graph_widget\u001b[39m.\u001b[39mset_edges(edges)\n\u001b[1;32m     59\u001b[0m graph_widget\u001b[39m.\u001b[39mset_node_color_mapping(custom_node_color)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nodes' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def custom_node_color(index: int, node: dict):\n",
    "  if 'node_type' in node['properties']:\n",
    "    if node['properties']['node_type'] == 'Entry':\n",
    "      return 'black'\n",
    "    elif node['properties']['node_type'] == 'Exit':\n",
    "      return 'black'\n",
    "    elif node['properties']['node_type'] == 'Timeline':\n",
    "      return '#3F6AFC'\n",
    "    elif node['properties']['node_type'] == 'Condition':\n",
    "      return '#ABB2B9'\n",
    "    elif node['properties']['node_type'] == 'CycleStart':\n",
    "      return '#3F6AFC'\n",
    "    elif node['properties']['node_type'] == 'Timing':\n",
    "      return '#6495ED'\n",
    "    elif node['properties']['node_type'] == 'Timepoint':\n",
    "      return '#ABB2B9'\n",
    "    elif node['properties']['node_type'] == 'Activity':\n",
    "      return '#1BA62F'\n",
    "    elif node['properties']['node_type'] == 'BCSurrogate':\n",
    "      return '#1BA62F'\n",
    "    elif node['properties']['node_type'] == 'Encounter':\n",
    "      return '#E53F2F'\n",
    "    elif node['properties']['node_type'] == 'StudyDesign':\n",
    "      return '#E52FDA'\n",
    "    elif node['properties']['node_type'] == 'Study':\n",
    "      return '#E52FDA'\n",
    "    else:\n",
    "      return 'white'\n",
    "  else: \n",
    "    return 'white'\n",
    "\n",
    "def custom_node_style(index: int, node: dict):\n",
    "  if 'node_type' in node['properties']:\n",
    "    if node['properties']['node_type'] == 'Entry' or node['properties']['node_type'] == 'Exit':\n",
    "      return {'image': 'https://raw.githubusercontent.com/data4knowledge/timepoints/main/images/pill_black.svg'}\n",
    "    elif node['properties']['node_type'] == 'Timeline':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    elif node['properties']['node_type'] == 'Timing':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    elif node['properties']['node_type'] == 'Condition':\n",
    "      return { 'shape': 'diamond' }\n",
    "    elif node['properties']['node_type'] == 'CycleStart':\n",
    "      return { 'shape': 'hexagon2' }\n",
    "    elif node['properties']['node_type'] == 'Timepoint':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    elif node['properties']['node_type'] == 'Activity':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    else:\n",
    "      return { 'shape': 'ellipse' }\n",
    "  else: \n",
    "    return { 'shape': 'ellipse' }\n",
    "\n",
    "graph_widget = GraphWidget()\n",
    "graph_widget.orthogonal_layout()\n",
    "graph_widget.set_directed(True)\n",
    "\n",
    "graph_widget.set_nodes(nodes)\n",
    "graph_widget.set_edges(edges)\n",
    "graph_widget.set_node_color_mapping(custom_node_color)\n",
    "graph_widget.set_node_styles_mapping(custom_node_style)\n",
    "graph_widget"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd128eb00d7d3f69b7bfbfdcc4e7f0c67a2eda7ab25ca8cb8c7708085581620b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
