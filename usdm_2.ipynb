{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: yfiles_jupyter_graphs in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.4.3)\n",
      "Requirement already satisfied: ipywidgets>=7.6.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from yfiles_jupyter_graphs) (8.0.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.8.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (8.8.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (6.20.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (4.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipywidgets>=7.6.0->yfiles_jupyter_graphs) (3.0.5)\n",
      "Requirement already satisfied: nest-asyncio in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.5.6)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (25.0.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.1.6)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (7.4.8)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.6.5)\n",
      "Requirement already satisfied: psutil in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.9.4)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (21.3)\n",
      "Requirement already satisfied: appnope in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.1.3)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.18.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (3.0.36)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (4.8.0)\n",
      "Requirement already satisfied: stack-data in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.6.2)\n",
      "Requirement already satisfied: decorator in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.1.1)\n",
      "Requirement already satisfied: backcall in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.13.0)\n",
      "Requirement already satisfied: pickleshare in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (5.1.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (3.0.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (0.2.2)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (1.16.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/daveih/Library/Python/3.10/lib/python/site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.0->yfiles_jupyter_graphs) (2.6.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install openpyxl\n",
    "%pip install yfiles_jupyter_graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from yfiles_jupyter_graphs import GraphWidget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_ROW = 0\n",
    "CYCLE_ROW = 1\n",
    "CYCLE_START_ROW = 2\n",
    "CYCLE_PERIOD_ROW = 3\n",
    "CYCLE_END_RULE_ROW = 4\n",
    "TIMING_ROW = 5\n",
    "VISIT_LABEL_ROW = 6\n",
    "VISIT_WINDOW_ROW = 7\n",
    "\n",
    "FIRST_ACTIVITY_ROW = 8\n",
    "\n",
    "ACTIVITY_COL = 0\n",
    "CHILD_ACTIVITY_COL = 1\n",
    "BC_COL = 2\n",
    "PROFILE_COL = 3\n",
    "FIRST_VISIT_COL = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cycle_cell(df, row_index, col_index):\n",
    "  is_null = pd.isnull(df.iloc[row_index, col_index])\n",
    "  if is_null:\n",
    "    return \"\", True\n",
    "  else:\n",
    "    value = str(df.iloc[row_index, col_index])\n",
    "    if value.upper() == \"-\":\n",
    "      return \"\", True\n",
    "    else:\n",
    "      return value, False\n",
    "\n",
    "def previous_index(index):\n",
    "  if index == 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return index - 1\n",
    "\n",
    "def build_cycle_record(df, index, col_index, condition):\n",
    "  cycle_start_index = index\n",
    "  cycle_start, is_null = get_cycle_cell(df, CYCLE_START_ROW, col_index)\n",
    "  cycle_period, is_null = get_cycle_cell(df, CYCLE_PERIOD_ROW, col_index)\n",
    "  cycle_end_rule, is_null = get_cycle_cell(df, CYCLE_END_RULE_ROW, col_index)\n",
    "  return { \n",
    "    'start_index': cycle_start_index, \n",
    "    'condition': condition, \n",
    "    'start': cycle_start, \n",
    "    'period': cycle_period, \n",
    "    'end_rule': cycle_end_rule \n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cycles(df):\n",
    "  cycles = []\n",
    "  timepoint_index = -1\n",
    "  cycle_start_index = None\n",
    "  in_cycle = False\n",
    "  prev_cycle = None\n",
    "  for col_index in range(df.shape[1]):\n",
    "    if col_index >= FIRST_VISIT_COL:\n",
    "      timepoint_index += 1\n",
    "      cycle, cycle_is_null = get_cycle_cell(df, CYCLE_ROW, col_index)\n",
    "      if cycle_is_null:\n",
    "        if in_cycle:\n",
    "          cycle_record['end_index'] = previous_index(timepoint_index)\n",
    "          cycles.append(cycle_record)\n",
    "          in_cycle = False\n",
    "        else:\n",
    "          pass # Do nothing\n",
    "      else:\n",
    "        cycle = str(cycle)\n",
    "        if not in_cycle:\n",
    "          in_cycle = True\n",
    "          cycle_record = build_cycle_record(df, timepoint_index, col_index, cycle)\n",
    "        elif prev_cycle == cycle:\n",
    "          pass # Do nothing\n",
    "        else:\n",
    "          cycle_record['end_index'] = previous_index(timepoint_index)\n",
    "          cycles.append(cycle_record)\n",
    "          cycle_record = build_cycle_record(df, timepoint_index, col_index, cycle)\n",
    "      prev_cycle = cycle\n",
    "  return cycles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timing_cell(df, row_index, col_index):\n",
    "  is_null = pd.isnull(df.iloc[row_index, col_index])\n",
    "  if is_null:\n",
    "    return \"\", True\n",
    "  else:\n",
    "    return df.iloc[row_index, col_index], False\n",
    "\n",
    "def get_relative_ref(part):\n",
    "  if len(part) > 1:\n",
    "    print(\"INT\", part, part[1:])\n",
    "    return int(part[1:])\n",
    "  else:\n",
    "    return 1\n",
    "\n",
    "def get_timing_type(df, col_index):\n",
    "  timing_type = \"\"\n",
    "  rel_ref = 0\n",
    "  timing_value = \"\"\n",
    "  timing_info, timing_info_is_null = get_timing_cell(df, TIMING_ROW, col_index)\n",
    "  if not timing_info_is_null:\n",
    "    timing_parts = timing_info.split(\":\")\n",
    "    if timing_parts[0].upper()[0] == \"A\":\n",
    "      timing_type = \"anchor\"\n",
    "      rel_ref = 0\n",
    "    if timing_parts[0].upper()[0] == \"P\":\n",
    "      timing_type = \"previous\"\n",
    "      rel_ref = get_relative_ref(timing_parts[0]) * -1\n",
    "    elif timing_parts[0].upper()[0] == \"N\":\n",
    "      timing_type = \"next\"\n",
    "      rel_ref = get_relative_ref(timing_parts[0])\n",
    "    if len(timing_parts) == 2:\n",
    "      timing_value = timing_parts[1].strip()\n",
    "  print(\"TIMING: col_index (%s) - FIRST_VISIT_COL (%s) + rel_ref (%s)\" % (col_index, FIRST_VISIT_COL, rel_ref))\n",
    "  return { 'type': timing_type, 'ref': col_index - FIRST_VISIT_COL + rel_ref, 'value': timing_value }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timepoints(df):\n",
    "  timepoints = []\n",
    "  for col_index in range(df.shape[1]):\n",
    "    if col_index >= FIRST_VISIT_COL:\n",
    "      record = get_timing_type(df, col_index)\n",
    "      timepoints.append(record)\n",
    "  return timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encounter_cell(df, row_index, col_index):\n",
    "  is_null = pd.isnull(df.iloc[row_index, col_index])\n",
    "  if is_null:\n",
    "    return \"\", True\n",
    "  else:\n",
    "    return df.iloc[row_index, col_index], False\n",
    "\n",
    "def get_encounter_details(df, col_index):\n",
    "  label = \"\"\n",
    "  window = \"\"\n",
    "  label, label_is_null = get_encounter_cell(df, VISIT_LABEL_ROW, col_index)\n",
    "  window, window_is_null = get_encounter_cell(df, VISIT_WINDOW_ROW, col_index)\n",
    "  return { 'label': label, 'window': window }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_encounters(df):\n",
    "  encounters = []\n",
    "  for col_index in range(df.shape[1]):\n",
    "    if col_index >= FIRST_VISIT_COL:\n",
    "      record = get_encounter_details(df, col_index)\n",
    "      encounters.append(record)\n",
    "  return encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_cell(df, row_index, col_index):\n",
    "  is_null = pd.isnull(df.iloc[row_index, col_index])\n",
    "  if is_null:\n",
    "    return \"\", True\n",
    "  else:\n",
    "    return df.iloc[row_index, col_index], False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activities_and_bcs(df):\n",
    "  activities = []\n",
    "  activities_bc_map = {}\n",
    "  row_activities_map = []\n",
    "  prev_activity = None\n",
    "  for row_index, col_def in df.iterrows():\n",
    "    if row_index >= FIRST_ACTIVITY_ROW:\n",
    "      activity, activity_is_null = get_activity_cell(df, row_index, CHILD_ACTIVITY_COL)\n",
    "      if activity_is_null:\n",
    "        if not prev_activity == None:\n",
    "          row_activities_map.append(prev_activity)\n",
    "      else:\n",
    "        activities.append(activity)\n",
    "        row_activities_map.append(activity)\n",
    "      prev_activity = activity\n",
    "      bc, bc_is_null = get_activity_cell(df, row_index, BC_COL)\n",
    "      if not bc_is_null:\n",
    "        if not activity in activities_bc_map:\n",
    "          activities_bc_map[activity] = { 'bc': [] }  \n",
    "        activities_bc_map[activity]['bc'].append(bc)\n",
    "  return { \n",
    "    'activities': activities,\n",
    "    'activity_bc_map': activities_bc_map,\n",
    "    'row_activities_map': row_activities_map\n",
    "  }\n",
    "\n",
    "def extract_timepoint_activities_map(df, timepoints, activities, row_activities_map):\n",
    "  timepoint_activity_map = []\n",
    "  activity_dict = {}\n",
    "  for activity in activities:\n",
    "    activity_dict[activity] = False\n",
    "  for tp in timepoints:\n",
    "    timepoint_activity_map.append(activity_dict)\n",
    "  for index in range(df.shape[1]):\n",
    "    if index >= FIRST_VISIT_COL:\n",
    "      column = df.iloc[:, index]\n",
    "      row = 0\n",
    "      for col in column:\n",
    "        if row >= FIRST_ACTIVITY_ROW:\n",
    "          if not pd.isnull(col):\n",
    "            if col.upper() == \"X\":\n",
    "              activity = row_activities_map[row - FIRST_ACTIVITY_ROW]\n",
    "              tp_index = index - FIRST_VISIT_COL\n",
    "              timepoint_activity_map[tp_index][activity] = True\n",
    "        row += 1\n",
    "  return timepoint_activity_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDFJson():\n",
    "  \n",
    "  def __init__(self):\n",
    "    self.id_index = { 'entry': 0, 'exit': 0, 'timepoint': 0, 'timeline': 0, 'timing': 0 }\n",
    "    self.dicts = {}\n",
    "\n",
    "  def increment_index(self, name):\n",
    "    self.id_index[name] += 1\n",
    "\n",
    "  def build_id(self, name):\n",
    "    self.increment_index(name)\n",
    "    return \"%s_%s\" % (name, self.id_index[name])\n",
    "\n",
    "  def add_entry(self, description, timepoint_id):\n",
    "    id = self.build_id('entry')\n",
    "    result = { 'entryId': id, 'entryDescription': description, 'timepoint': timepoint_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_exit(self):\n",
    "    id = self.build_id('exit')\n",
    "    result = { 'exitId': id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_timepoint(self, previous_timepoint_id, timing):\n",
    "    id = self.build_id('timepoint')\n",
    "    result = { 'timepointId': id, 'nextTimepointId': None, 'scheduledAt': timing }\n",
    "    self.dicts[id] = result\n",
    "    if not previous_timepoint_id == None:\n",
    "      self.dicts[previous_timepoint_id]['nextTimepointId'] = id\n",
    "    return result\n",
    "\n",
    "  def add_previous_timing(self, value, relative_to_from, window, to_id):\n",
    "    id = self.build_id('timing')\n",
    "    result = { 'timingId': id, 'type': \"after\", 'value': value, 'relativeToFrom': relative_to_from, 'window': window, 'relativeTo': to_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_next_timing(self, value, relative_to_from, window, to_id):\n",
    "    id = self.build_id('timing')\n",
    "    result = { 'timingId': id, 'type': \"next\", 'value': value, 'relativeToFrom': relative_to_from, 'window': window, 'relativeTo': to_id }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_anchor_timing(self, value):\n",
    "    id = self.build_id('timing')\n",
    "    result = { 'timingId': id, 'type': \"anchor\", 'value': value, 'relativeToFrom': None, 'window': None, 'relativeTo': None }\n",
    "    self.dicts[id] = result\n",
    "    return result\n",
    "\n",
    "  def add_timeline(self, entry, timepoints, exit):\n",
    "    id = self.build_id('timeline')\n",
    "    result = { 'timelineId': self.build_id('timeline'), 'timelineEntry': entry, 'timelineTimepoints': timepoints, 'timelineExit': exit }\n",
    "    return result\n",
    "  \n",
    "  def process_timepoints(self, timepoints):\n",
    "    tps = []\n",
    "    timing = []\n",
    "    previous_tp_id = None\n",
    "    for timepoint in timepoints:\n",
    "      tps.append(self.add_timepoint(previous_tp_id, None))\n",
    "      previous_tp_id = tps[-1]['timepointId']\n",
    "    for timepoint in timepoints:\n",
    "      if timepoint['type'] == 'next':\n",
    "        timing.append(self.add_next_timing(timepoint['value'], 'StartToStart', None, tps[timepoint['ref']]['timepointId']))\n",
    "      elif timepoint['type'] == 'previous':\n",
    "        timing.append(self.add_previous_timing(timepoint['value'], 'StartToStart', None, tps[timepoint['ref']]['timepointId']))\n",
    "      elif timepoint['type'] == 'anchor':\n",
    "        timing.append(self.add_anchor_timing(timepoint['value']))\n",
    "      elif timepoint['type'] == '':\n",
    "        timing.append({})\n",
    "    for index, tp in enumerate(tps):\n",
    "      tp['scheduledAt'] = timing[index]\n",
    "    entry = self.add_entry('Main timeline', tps[0]['timepointId'])\n",
    "    exit = self.add_exit()\n",
    "    tps[-1]['exit'] = exit\n",
    "    return self.add_timeline(entry, tps, exit)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_node_color(index: int, node: dict):\n",
    "  if 'node_type' in node['properties']:\n",
    "    if node['properties']['node_type'] == 'entry_exit':\n",
    "      return 'black'\n",
    "    elif node['properties']['node_type'] == 'anchor':\n",
    "      return 'black'\n",
    "    elif node['properties']['node_type'] == 'condition':\n",
    "      return 'black'\n",
    "    elif node['properties']['node_type'] == 'timepoint':\n",
    "      return 'black'\n",
    "    elif node['properties']['node_type'] == 'visit':\n",
    "      return '#c1141a'\n",
    "    elif node['properties']['node_type'] == 'activity':\n",
    "      return '#1555bd'\n",
    "    elif node['properties']['node_type'] == 'bc':\n",
    "      return '#c0d6e4'\n",
    "    else:\n",
    "      return 'white'\n",
    "  else: \n",
    "    return 'white'\n",
    "\n",
    "def custom_node_style(index: int, node: dict):\n",
    "  if 'node_type' in node['properties']:\n",
    "    if node['properties']['node_type'] == 'entry_exit':\n",
    "      #return { 'shape': 'round-rectangle' }\n",
    "      return {\n",
    "        'image': 'https://raw.githubusercontent.com/data4knowledge/timepoints/main/images/pill_black.svg'\n",
    "        #'image': 'https://gist.githubusercontent.com/fskpf/b5c5b765139056ddc7e72ea28d4f44e4/raw/f4483469a9d4f638a8acae39aa6adfd76b61f587/yfiles-jupyter-graphs-icon.svg'\n",
    "      }\n",
    "    elif node['properties']['node_type'] == 'anchor':\n",
    "      return { 'shape': 'hexagon2' }\n",
    "    elif node['properties']['node_type'] == 'condition':\n",
    "      return { 'shape': 'diamond' }\n",
    "    elif node['properties']['node_type'] == 'timepoint':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    elif node['properties']['node_type'] == 'visit':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    elif node['properties']['node_type'] == 'activity':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    elif node['properties']['node_type'] == 'bc':\n",
    "      return { 'shape': 'ellipse' }\n",
    "    else:\n",
    "      return { 'shape': 'ellipse' }\n",
    "  else: \n",
    "    return { 'shape': 'ellipse' }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMING: col_index (4) - FIRST_VISIT_COL (4) + rel_ref (1)\n",
      "TIMING: col_index (5) - FIRST_VISIT_COL (4) + rel_ref (0)\n",
      "TIMING: col_index (6) - FIRST_VISIT_COL (4) + rel_ref (-1)\n",
      "TIMING: col_index (7) - FIRST_VISIT_COL (4) + rel_ref (0)\n",
      "TIMING: col_index (8) - FIRST_VISIT_COL (4) + rel_ref (-1)\n",
      "INT P4 4\n",
      "TIMING: col_index (9) - FIRST_VISIT_COL (4) + rel_ref (-4)\n",
      "INT P1 1\n",
      "TIMING: col_index (10) - FIRST_VISIT_COL (4) + rel_ref (-1)\n",
      "TIMING: col_index (11) - FIRST_VISIT_COL (4) + rel_ref (0)\n",
      "TIMING: col_index (12) - FIRST_VISIT_COL (4) + rel_ref (0)\n",
      "TIMING: col_index (13) - FIRST_VISIT_COL (4) + rel_ref (-1)\n",
      "TIMING: col_index (14) - FIRST_VISIT_COL (4) + rel_ref (-1)\n",
      "CYCLES [{'start_index': 1, 'condition': '1', 'start': 'Day 1', 'period': '15 Days', 'end_rule': '', 'end_index': 2}, {'start_index': 3, 'condition': '2', 'start': 'Day 16', 'period': '15 Days', 'end_rule': '', 'end_index': 4}, {'start_index': 5, 'condition': '3', 'start': 'Day 31', 'period': '15 Days', 'end_rule': '', 'end_index': 6}, {'start_index': 7, 'condition': '4..12', 'start': 'Day 46', 'period': '15 Days', 'end_rule': '', 'end_index': 7}, {'start_index': 8, 'condition': '13 .. N step 3', 'start': 'Day 211', 'period': '15 Days', 'end_rule': 'Disease Progresssion', 'end_index': 8}]\n",
      "TIMEPOINTS [{'type': 'next', 'ref': 1, 'value': '0..30 Days'}, {'type': 'anchor', 'ref': 1, 'value': 'Day 1'}, {'type': 'previous', 'ref': 1, 'value': '+14 Days'}, {'type': 'anchor', 'ref': 3, 'value': 'Day 16'}, {'type': 'previous', 'ref': 3, 'value': '+14 Days'}, {'type': 'previous', 'ref': 1, 'value': '+30 Days'}, {'type': 'previous', 'ref': 5, 'value': '+14 Days'}, {'type': '', 'ref': 7, 'value': ''}, {'type': '', 'ref': 8, 'value': ''}, {'type': 'previous', 'ref': 8, 'value': 'Within 30 days of last dose'}, {'type': 'previous', 'ref': 9, 'value': '+12 weeks'}]\n",
      "ENCOUNTERS [{'label': '-', 'window': '-'}, {'label': 'Day 1', 'window': '-'}, {'label': 'Day 15', 'window': '-2..2 Days'}, {'label': 'Day 1', 'window': '-2..2 Days'}, {'label': 'Day 15', 'window': '-2..2 Days'}, {'label': 'Day 1', 'window': '-2..2 Days'}, {'label': 'Day 15', 'window': '-2..2 Days'}, {'label': 'Day 1', 'window': '-2..2 Days'}, {'label': 'Day 1', 'window': '-2..2 Days'}, {'label': 'EOT Visit', 'window': '0..5 Days'}, {'label': 'FU Visit', 'window': '0..2 Weeks'}]\n",
      "ACTIVITIES {'activities': ['Child Activity', 'Informed Consent', 'Inclusion / Exclusion Criteria', 'Physical Examination', '-', '-', '-'], 'activity_bc_map': {'Child Activity': {'bc': ['BCs']}, 'Informed Consent': {'bc': ['-']}, 'Inclusion / Exclusion Criteria': {'bc': ['-']}, 'Physical Examination': {'bc': ['PE 1']}, '-': {'bc': ['PE 2', 'Weight', 'Height']}}, 'row_activities_map': ['Child Activity', 'Informed Consent', 'Inclusion / Exclusion Criteria', 'Physical Examination', '-', '-', '-']}\n",
      "TP ACTIVITIES [{'Child Activity': False, 'Informed Consent': True, 'Inclusion / Exclusion Criteria': True, 'Physical Examination': True, '-': False}, {'Child Activity': False, 'Informed Consent': True, 'Inclusion / Exclusion Criteria': True, 'Physical Examination': True, '-': False}, {'Child Activity': False, 'Informed Consent': True, 'Inclusion / Exclusion Criteria': True, 'Physical Examination': True, '-': False}, {'Child Activity': False, 'Informed Consent': True, 'Inclusion / Exclusion Criteria': True, 'Physical Examination': True, '-': False}, {'Child Activity': False, 'Informed Consent': True, 'Inclusion / Exclusion Criteria': True, 'Physical Examination': True, '-': False}, {'Child Activity': False, 'Informed Consent': True, 'Inclusion / Exclusion Criteria': True, 'Physical Examination': True, '-': False}, {'Child Activity': False, 'Informed Consent': True, 'Inclusion / Exclusion Criteria': True, 'Physical Examination': True, '-': False}, {'Child Activity': False, 'Informed Consent': True, 'Inclusion / Exclusion Criteria': True, 'Physical Examination': True, '-': False}, {'Child Activity': False, 'Informed Consent': True, 'Inclusion / Exclusion Criteria': True, 'Physical Examination': True, '-': False}, {'Child Activity': False, 'Informed Consent': True, 'Inclusion / Exclusion Criteria': True, 'Physical Examination': True, '-': False}, {'Child Activity': False, 'Informed Consent': True, 'Inclusion / Exclusion Criteria': True, 'Physical Examination': True, '-': False}]\n",
      "X: {'timelineId': 'timeline_2', 'timelineEntry': {'entryId': 'entry_1', 'entryDescription': 'Main timeline', 'timepoint': 'timepoint_1'}, 'timelineTimepoints': [{'timepointId': 'timepoint_1', 'nextTimepointId': 'timepoint_2', 'scheduledAt': {'timeingId': 'timing_1', 'type': 'next', 'value': '0..30 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}}, {'timepointId': 'timepoint_2', 'nextTimepointId': 'timepoint_3', 'scheduledAt': {'timeingId': 'timing_2', 'type': 'anchor', 'value': 'Day 1', 'relativeToFrom': None, 'window': None, 'relativeTo': None}}, {'timepointId': 'timepoint_3', 'nextTimepointId': 'timepoint_4', 'scheduledAt': {'timeingId': 'timing_3', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}}, {'timepointId': 'timepoint_4', 'nextTimepointId': 'timepoint_5', 'scheduledAt': {'timeingId': 'timing_4', 'type': 'anchor', 'value': 'Day 16', 'relativeToFrom': None, 'window': None, 'relativeTo': None}}, {'timepointId': 'timepoint_5', 'nextTimepointId': 'timepoint_6', 'scheduledAt': {'timeingId': 'timing_5', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_4'}}, {'timepointId': 'timepoint_6', 'nextTimepointId': 'timepoint_7', 'scheduledAt': {'timeingId': 'timing_6', 'type': 'after', 'value': '+30 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_2'}}, {'timepointId': 'timepoint_7', 'nextTimepointId': 'timepoint_8', 'scheduledAt': {'timeingId': 'timing_7', 'type': 'after', 'value': '+14 Days', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_6'}}, {'timepointId': 'timepoint_8', 'nextTimepointId': 'timepoint_9', 'scheduledAt': {}}, {'timepointId': 'timepoint_9', 'nextTimepointId': 'timepoint_10', 'scheduledAt': {}}, {'timepointId': 'timepoint_10', 'nextTimepointId': 'timepoint_11', 'scheduledAt': {'timeingId': 'timing_8', 'type': 'after', 'value': 'Within 30 days of last dose', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_9'}}, {'timepointId': 'timepoint_11', 'nextTimepointId': None, 'scheduledAt': {'timeingId': 'timing_9', 'type': 'after', 'value': '+12 weeks', 'relativeToFrom': 'StartToStart', 'window': None, 'relativeTo': 'timepoint_10'}, 'exit': {'exitId': 'exit_1'}}], 'timelineExit': {'exitId': 'exit_1'}}\n"
     ]
    }
   ],
   "source": [
    "notebook_path = os.path.abspath(\"notebook.ipynb\")\n",
    "file_path = os.path.join(os.path.dirname(notebook_path), \"source_data/berber_1_v2.xlsx\")\n",
    "#file_path = os.path.join(os.path.dirname(notebook_path), \"source_data/Roche Phase 3 NCT04320615.xlsx\")\n",
    "df = pd.read_excel(file_path, header=None)\n",
    "df = df.fillna(method='ffill', axis=1)\n",
    "cycles = extract_cycles(df)\n",
    "timepoints = extract_timepoints(df)\n",
    "encounters = extract_encounters(df)\n",
    "activities = extract_activities_and_bcs(df)\n",
    "tp_activities = extract_timepoint_activities_map(df, timepoints, activities['activities'], activities['row_activities_map'])\n",
    "print(\"CYCLES\", cycles)\n",
    "print(\"TIMEPOINTS\", timepoints)\n",
    "print(\"ENCOUNTERS\", encounters)\n",
    "print(\"ACTIVITIES\", activities)\n",
    "print(\"TP ACTIVITIES\", tp_activities)\n",
    "\n",
    "x = DDFJson()\n",
    "json = x.process_timepoints(timepoints)\n",
    "print(\"X:\", json)\n",
    "\n",
    "#nodes, edges = prepare_nodes_and_edges(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w = GraphWidget()\n",
    "#w.orthogonal_layout()\n",
    "#w.set_directed(True)\n",
    "\n",
    "#w.set_nodes(nodes)\n",
    "#w.set_edges(edges)\n",
    "\n",
    "#w.set_node_color_mapping(custom_node_color)\n",
    "#w.set_node_styles_mapping(custom_node_style)\n",
    "#w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
